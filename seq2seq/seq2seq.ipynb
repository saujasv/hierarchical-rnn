{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of Questions with a seq2seq network \n",
    "*************************************************************\n",
    "\n",
    "[KEY: > input, = target, < output]\n",
    "\n",
    "   \n",
    "\n",
    "This is made possible by the simple but powerful idea of the `sequence\n",
    "to sequence network <http://arxiv.org/abs/1409.3215>`__, in which two\n",
    "recurrent neural networks work together to transform one sequence to\n",
    "another. An encoder network condenses an input sequence into a vector,\n",
    "and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "\n",
    "\n",
    "To improve upon this model we'll use an `attention\n",
    "mechanism <https://arxiv.org/abs/1409.0473>`__, which lets the decoder\n",
    "learn to focus over a specific range of the input sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data files\n",
    "===================\n",
    "\n",
    "The data for this project is a set of many thousands of sentence pairs, broken down into two main groups i.e agreement and no agreement and are present in the dataset folder of the project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the character encoding used in the character-level RNN\n",
    "tutorials, we will be representing each word in a language as a one-hot\n",
    "vector, or giant vector of zeros except for a single one (at the index\n",
    "of the word). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a unique index per word to use as the inputs and targets of\n",
    "the networks later. To keep track of all this we will use a helper class\n",
    "called ``Lang`` which has word → index (``word2index``) and index → word\n",
    "(``index2word``) dictionaries, as well as a count of each word\n",
    "``word2count`` to use to later replace rare words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "IDENT_TOKEN = -1\n",
    "QUEST_TOKEN = -1\n",
    "EOS_TOKEN =1\n",
    "input_file_path = \"./../data/agreement/\"\n",
    "agreement = True\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall convert all the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts all to lowercase\n",
    "def normalizeString(s):\n",
    "    s = (s.lower().strip())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split\n",
    "lines into pairs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(input_file_path+'train.txt' ,).\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum length of each sentence has been set to a 100 words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100\n",
    "\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "-  Read text file and split into lines, split lines into pairs\n",
    "-  Normalize text, filter by length and content\n",
    "-  Make word lists from sentences in pairs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 116600 sentence pairs\n",
      "Trimmed to 116600 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "inp 55\n",
      "out 56\n",
      "['her unicorn who doesnt read doesnt confuse the unicorn by her unicorn . ident', 'her unicorn who doesnt read doesnt confuse the unicorn by her unicorn . ident']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('out', 'inp', True)\n",
    "IDENT_TOKEN = input_lang.word2index[\"ident\"]\n",
    "QUEST_TOKEN = input_lang.word2index[\"quest\"]\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Seq2Seq Model\n",
    "=================\n",
    "\n",
    "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
    "sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "A `Sequence to Sequence network <http://arxiv.org/abs/1409.3215>`__, or\n",
    "seq2seq network, or `Encoder Decoder\n",
    "network <https://arxiv.org/pdf/1406.1078v3.pdf>`__, is a model\n",
    "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
    "an input sequence and outputs a single vector, and the decoder reads\n",
    "that vector to produce an output sequence.\n",
    "\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input\n",
    "corresponds to an output, the seq2seq model frees us from sequence\n",
    "length and order, which makes it ideal for translation between two\n",
    "languages.\n",
    "\n",
    "With a seq2seq model the encoder creates a single vector which, in the\n",
    "ideal case, encodes the \"meaning\" of the input sequence into a single\n",
    "vector — a single point in some N dimensional space of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Encoder\n",
    "-----------\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for\n",
    "every word from the input sentence. For every input word the encoder\n",
    "outputs a vector and a hidden state, and uses the hidden state for the\n",
    "next input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.randn(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decoder\n",
    "-----------\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector(s) and\n",
    "outputs a sequence of words to create the translation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Decoder\n",
    "-----------\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder.\n",
    "This last output is sometimes called the *context vector* as it encodes\n",
    "context from the entire sequence. This context vector is used as the\n",
    "initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and\n",
    "hidden state. The initial input token is the start-of-string ``<SOS>``\n",
    "token, and the first hidden state is the context vector (the encoder's\n",
    "last hidden state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.randn(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Decoder\n",
    "-----------\n",
    "\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder,\n",
    "that single vector carries the burden of encoding the entire sentence.\n",
    "\n",
    "Attention allows the decoder network to \"focus\" on a different part of\n",
    "the encoder's outputs for every step of the decoder's own outputs. First\n",
    "we calculate a set of *attention weights*. These will be multiplied by\n",
    "the encoder output vectors to create a weighted combination. The result\n",
    "(called ``attn_applied`` in the code) should contain information about\n",
    "that specific part of the input sequence, and thus help the decoder\n",
    "choose the right output words.\n",
    "\n",
    "\n",
    "Calculating the attention weights is done with another feed-forward\n",
    "layer ``attn``, using the decoder's input and hidden state as inputs.\n",
    "Because there are sentences of all sizes in the training data, to\n",
    "actually create and train this layer we have to choose a maximum\n",
    "sentence length (input length, for encoder outputs) that it can apply\n",
    "to. Sentences of the maximum length will use all the attention weights,\n",
    "while shorter sentences will only use the first few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.randn(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Training\n",
    "========\n",
    "\n",
    "Preparing Training Data\n",
    "-----------------------\n",
    "\n",
    "To train, for each pair we will need an input tensor (indexes of the\n",
    "words in the input sentence) and target tensor (indexes of the words in\n",
    "the target sentence). While creating these vectors we will append the\n",
    "EOS token to both sequences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    if(indexes[-1]!=lang.word2index[\"ident\"] and indexes[-1]!=lang.word2index[\"quest\"]):\n",
    "        indexes.append(EOS_TOKEN)\n",
    "        \n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model\n",
    "------------------\n",
    "\n",
    "To train we run the input sentence through the encoder, and keep track\n",
    "of every output and the latest hidden state. Then the decoder is given\n",
    "the ``<SOS>`` token as its first input, and the last hidden state of the\n",
    "encoder as its first hidden state.\n",
    "\n",
    "\"Teacher forcing\" is the concept of using the real target outputs as\n",
    "each next input, instead of using the decoder's guess as the next input.\n",
    "Using teacher forcing causes it to converge faster but `when the trained\n",
    "network is exploited, it may exhibit\n",
    "instability <http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf>`__.\n",
    "\n",
    "You can observe outputs of teacher-forced networks that read with\n",
    "coherent grammar but wander far from the correct translation -\n",
    "intuitively it has learned to represent the output grammar and can \"pick\n",
    "up\" the meaning once the teacher tells it the first few words, but it\n",
    "has not properly learned how to create the sentence from the translation\n",
    "in the first place.\n",
    "\n",
    "Because of the freedom PyTorch's autograd gives us, we can randomly\n",
    "choose to use teacher forcing or not with a simple if statement. Turn\n",
    "``teacher_forcing_ratio`` up to use more of it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the cats do sleep . quest', 'do the cats sleep ? quest']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7]]), tensor([[2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7]]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pairs[0])\n",
    "tensorsFromPair(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == IDENT_TOKEN or decoder_input.item() == QUEST_TOKEN or decoder_input.item()== EOS_TOKEN:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to print time elapsed and estimated time\n",
    "remaining given the current time and progress %.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "-  Start a timer\n",
    "-  Initialize optimizers and criterion\n",
    "-  Create set of training pairs\n",
    "-  Start empty losses array for plotting\n",
    "\n",
    "Then we call ``train`` many times and occasionally print the progress (%\n",
    "of examples, time so far, estimated time) and average loss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting results\n",
    "----------------\n",
    "\n",
    "Plotting is done with matplotlib, using the array of loss values\n",
    "``plot_losses`` saved while training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "==========\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so\n",
    "we simply feed the decoder's predictions back to itself for each step.\n",
    "Every time it predicts a word we add it to the output string, and if it\n",
    "predicts the EOS token we stop there. We also store the decoder's\n",
    "attention outputs for display later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == IDENT_TOKEN :\n",
    "                decoded_words.append('<IDENT>')\n",
    "                break\n",
    "            elif topi.item() == QUEST_TOKEN :\n",
    "                decoded_words.append('<QUEST>')\n",
    "                break\n",
    "            elif topi.item() == EOS_TOKEN :\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the\n",
    "input, target, and output to make some subjective quality judgements:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Evaluating\n",
    "=======================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "param_groups \t [{'lr': 0.001, 'weight_decay': 0, 'momentum': 0.9, 'dampening': 0, 'nesterov': False, 'params': [139930092388568, 139930092388640, 139930092388712, 139930092388784, 139930092388856, 139930092388928, 139930092389000, 139930092389072, 139930092389144, 139930092389216]}]\n",
      "state \t {}\n"
     ]
    }
   ],
   "source": [
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agreement_1.pt\n",
      "0m 3s (- 78m 51s) (50 0%) 0.0449\n",
      "0m 4s (- 56m 40s) (100 0%) 0.0384\n",
      "0m 5s (- 48m 28s) (150 0%) 0.0449\n",
      "0m 7s (- 44m 53s) (200 0%) 0.0372\n",
      "0m 8s (- 42m 37s) (250 0%) 0.0442\n",
      "0m 9s (- 40m 56s) (300 0%) 0.0374\n",
      "0m 11s (- 39m 17s) (350 0%) 0.0248\n",
      "0m 12s (- 38m 26s) (400 0%) 0.0500\n",
      "0m 13s (- 38m 0s) (450 0%) 0.0427\n",
      "0m 15s (- 37m 15s) (500 0%) 0.0250\n",
      "0m 16s (- 36m 54s) (550 0%) 0.0412\n",
      "0m 17s (- 36m 37s) (600 0%) 0.0447\n",
      "0m 19s (- 36m 32s) (650 0%) 0.0575\n",
      "0m 20s (- 36m 8s) (700 0%) 0.0316\n",
      "0m 21s (- 35m 46s) (750 1%) 0.0456\n",
      "0m 22s (- 35m 32s) (800 1%) 0.0480\n",
      "0m 24s (- 35m 19s) (850 1%) 0.0414\n",
      "0m 25s (- 35m 4s) (900 1%) 0.0737\n",
      "0m 26s (- 34m 52s) (950 1%) 0.0631\n",
      "0m 28s (- 34m 44s) (1000 1%) 0.0301\n",
      "0m 29s (- 34m 30s) (1050 1%) 0.0318\n",
      "0m 30s (- 34m 11s) (1100 1%) 0.0401\n",
      "0m 31s (- 34m 4s) (1150 1%) 0.0339\n",
      "0m 33s (- 33m 57s) (1200 1%) 0.0727\n",
      "0m 34s (- 33m 55s) (1250 1%) 0.0444\n",
      "0m 35s (- 33m 49s) (1300 1%) 0.0552\n",
      "0m 37s (- 33m 44s) (1350 1%) 0.0386\n",
      "0m 38s (- 33m 36s) (1400 1%) 0.0354\n",
      "0m 39s (- 33m 34s) (1450 1%) 0.0472\n",
      "0m 41s (- 33m 32s) (1500 2%) 0.0597\n",
      "0m 42s (- 33m 28s) (1550 2%) 0.0325\n",
      "0m 43s (- 33m 26s) (1600 2%) 0.0277\n",
      "0m 45s (- 33m 24s) (1650 2%) 0.0532\n",
      "0m 46s (- 33m 19s) (1700 2%) 0.0504\n",
      "0m 47s (- 33m 10s) (1750 2%) 0.0609\n",
      "0m 48s (- 33m 7s) (1800 2%) 0.0485\n",
      "0m 50s (- 33m 4s) (1850 2%) 0.0312\n",
      "0m 51s (- 33m 4s) (1900 2%) 0.0394\n",
      "0m 52s (- 33m 1s) (1950 2%) 0.0413\n",
      "0m 54s (- 32m 59s) (2000 2%) 0.0298\n",
      "0m 55s (- 32m 57s) (2050 2%) 0.0369\n",
      "0m 56s (- 32m 54s) (2100 2%) 0.0586\n",
      "0m 58s (- 32m 53s) (2150 2%) 0.0392\n",
      "0m 59s (- 32m 49s) (2200 2%) 0.0248\n",
      "1m 0s (- 32m 46s) (2250 3%) 0.0299\n",
      "1m 2s (- 32m 47s) (2300 3%) 0.0511\n",
      "1m 3s (- 32m 45s) (2350 3%) 0.0285\n",
      "1m 5s (- 32m 48s) (2400 3%) 0.0433\n",
      "1m 6s (- 32m 48s) (2450 3%) 0.0340\n",
      "1m 7s (- 32m 48s) (2500 3%) 0.0431\n",
      "1m 9s (- 32m 48s) (2550 3%) 0.0352\n",
      "1m 10s (- 32m 47s) (2600 3%) 0.0372\n",
      "1m 12s (- 32m 47s) (2650 3%) 0.0276\n",
      "1m 13s (- 32m 46s) (2700 3%) 0.0322\n",
      "1m 14s (- 32m 46s) (2750 3%) 0.0335\n",
      "1m 16s (- 32m 44s) (2800 3%) 0.0257\n",
      "1m 17s (- 32m 42s) (2850 3%) 0.0455\n",
      "1m 18s (- 32m 41s) (2900 3%) 0.0348\n",
      "1m 20s (- 32m 38s) (2950 3%) 0.0301\n",
      "1m 21s (- 32m 34s) (3000 4%) 0.0203\n",
      "1m 22s (- 32m 33s) (3050 4%) 0.0405\n",
      "1m 24s (- 32m 32s) (3100 4%) 0.0285\n",
      "1m 25s (- 32m 30s) (3150 4%) 0.0364\n",
      "1m 26s (- 32m 29s) (3200 4%) 0.0554\n",
      "1m 28s (- 32m 25s) (3250 4%) 0.0389\n",
      "1m 29s (- 32m 21s) (3300 4%) 0.0310\n",
      "1m 30s (- 32m 22s) (3350 4%) 0.0355\n",
      "1m 32s (- 32m 22s) (3400 4%) 0.0188\n",
      "1m 33s (- 32m 21s) (3450 4%) 0.0248\n",
      "1m 35s (- 32m 21s) (3500 4%) 0.0377\n",
      "1m 36s (- 32m 20s) (3550 4%) 0.0383\n",
      "1m 37s (- 32m 16s) (3600 4%) 0.0368\n",
      "1m 39s (- 32m 16s) (3650 4%) 0.0332\n",
      "1m 40s (- 32m 15s) (3700 4%) 0.0277\n",
      "1m 41s (- 32m 14s) (3750 5%) 0.0321\n",
      "1m 43s (- 32m 11s) (3800 5%) 0.0314\n",
      "1m 44s (- 32m 10s) (3850 5%) 0.0200\n",
      "1m 45s (- 32m 9s) (3900 5%) 0.0376\n",
      "1m 47s (- 32m 6s) (3950 5%) 0.0356\n",
      "1m 48s (- 32m 4s) (4000 5%) 0.0387\n",
      "1m 49s (- 32m 3s) (4050 5%) 0.0279\n",
      "1m 51s (- 32m 3s) (4100 5%) 0.0329\n",
      "1m 52s (- 32m 1s) (4150 5%) 0.0275\n",
      "1m 53s (- 32m 1s) (4200 5%) 0.0251\n",
      "1m 55s (- 32m 0s) (4250 5%) 0.0354\n",
      "1m 56s (- 32m 0s) (4300 5%) 0.0214\n",
      "1m 58s (- 32m 0s) (4350 5%) 0.0532\n",
      "1m 59s (- 31m 59s) (4400 5%) 0.0268\n",
      "2m 1s (- 32m 1s) (4450 5%) 0.0350\n",
      "2m 2s (- 32m 2s) (4500 6%) 0.0361\n",
      "2m 4s (- 32m 3s) (4550 6%) 0.0303\n",
      "2m 5s (- 32m 3s) (4600 6%) 0.0542\n",
      "2m 7s (- 32m 3s) (4650 6%) 0.0296\n",
      "2m 8s (- 32m 3s) (4700 6%) 0.0390\n",
      "2m 10s (- 32m 2s) (4750 6%) 0.0245\n",
      "2m 11s (- 31m 59s) (4800 6%) 0.0244\n",
      "2m 12s (- 31m 59s) (4850 6%) 0.0446\n",
      "2m 14s (- 31m 59s) (4900 6%) 0.0213\n",
      "2m 15s (- 31m 59s) (4950 6%) 0.0428\n",
      "2m 17s (- 31m 58s) (5000 6%) 0.0405\n",
      "2m 18s (- 31m 57s) (5050 6%) 0.0229\n",
      "2m 19s (- 31m 57s) (5100 6%) 0.0462\n",
      "2m 21s (- 31m 57s) (5150 6%) 0.0481\n",
      "2m 22s (- 31m 57s) (5200 6%) 0.0457\n",
      "2m 24s (- 31m 56s) (5250 7%) 0.0276\n",
      "2m 25s (- 31m 54s) (5300 7%) 0.0189\n",
      "2m 27s (- 31m 53s) (5350 7%) 0.0209\n",
      "2m 28s (- 31m 52s) (5400 7%) 0.0487\n",
      "2m 29s (- 31m 51s) (5450 7%) 0.0317\n",
      "2m 31s (- 31m 50s) (5500 7%) 0.0172\n",
      "2m 32s (- 31m 50s) (5550 7%) 0.0262\n",
      "2m 33s (- 31m 47s) (5600 7%) 0.0323\n",
      "2m 35s (- 31m 46s) (5650 7%) 0.1082\n",
      "2m 36s (- 31m 45s) (5700 7%) 0.0324\n",
      "2m 38s (- 31m 44s) (5750 7%) 0.0363\n",
      "2m 39s (- 31m 43s) (5800 7%) 0.0329\n",
      "2m 40s (- 31m 42s) (5850 7%) 0.0129\n",
      "2m 42s (- 31m 41s) (5900 7%) 0.0413\n",
      "2m 43s (- 31m 41s) (5950 7%) 0.0345\n",
      "2m 45s (- 31m 40s) (6000 8%) 0.0390\n",
      "2m 46s (- 31m 41s) (6050 8%) 0.0250\n",
      "2m 48s (- 31m 40s) (6100 8%) 0.0216\n",
      "2m 49s (- 31m 39s) (6150 8%) 0.0241\n",
      "2m 51s (- 31m 39s) (6200 8%) 0.0289\n",
      "2m 52s (- 31m 39s) (6250 8%) 0.0303\n",
      "2m 54s (- 31m 43s) (6300 8%) 0.0280\n",
      "2m 56s (- 31m 43s) (6350 8%) 0.0255\n",
      "2m 57s (- 31m 42s) (6400 8%) 0.0292\n",
      "2m 58s (- 31m 41s) (6450 8%) 0.0397\n",
      "3m 0s (- 31m 40s) (6500 8%) 0.0238\n",
      "3m 1s (- 31m 38s) (6550 8%) 0.0255\n",
      "3m 3s (- 31m 37s) (6600 8%) 0.0479\n",
      "3m 4s (- 31m 36s) (6650 8%) 0.0305\n",
      "3m 5s (- 31m 35s) (6700 8%) 0.0294\n",
      "3m 7s (- 31m 35s) (6750 9%) 0.0480\n",
      "3m 8s (- 31m 33s) (6800 9%) 0.0345\n",
      "3m 10s (- 31m 33s) (6850 9%) 0.0315\n",
      "3m 11s (- 31m 33s) (6900 9%) 0.1180\n",
      "3m 13s (- 31m 32s) (6950 9%) 0.0327\n",
      "3m 14s (- 31m 31s) (7000 9%) 0.0356\n",
      "3m 16s (- 31m 29s) (7050 9%) 0.0277\n",
      "3m 17s (- 31m 29s) (7100 9%) 0.0414\n",
      "3m 19s (- 31m 28s) (7150 9%) 0.0314\n",
      "3m 20s (- 31m 27s) (7200 9%) 0.0429\n",
      "3m 22s (- 31m 27s) (7250 9%) 0.0284\n",
      "3m 23s (- 31m 27s) (7300 9%) 0.0265\n",
      "3m 25s (- 31m 26s) (7350 9%) 0.0324\n",
      "3m 26s (- 31m 26s) (7400 9%) 0.0265\n",
      "3m 27s (- 31m 25s) (7450 9%) 0.0206\n",
      "3m 29s (- 31m 24s) (7500 10%) 0.0238\n",
      "3m 30s (- 31m 23s) (7550 10%) 0.0328\n",
      "3m 32s (- 31m 22s) (7600 10%) 0.0258\n",
      "3m 33s (- 31m 21s) (7650 10%) 0.0357\n",
      "3m 34s (- 31m 18s) (7700 10%) 0.0137\n",
      "3m 36s (- 31m 17s) (7750 10%) 0.0292\n",
      "3m 37s (- 31m 17s) (7800 10%) 0.0270\n",
      "3m 39s (- 31m 16s) (7850 10%) 0.0133\n",
      "3m 40s (- 31m 16s) (7900 10%) 0.0406\n",
      "3m 42s (- 31m 15s) (7950 10%) 0.0250\n",
      "3m 43s (- 31m 14s) (8000 10%) 0.0271\n",
      "3m 45s (- 31m 14s) (8050 10%) 0.0221\n",
      "3m 46s (- 31m 13s) (8100 10%) 0.0265\n",
      "3m 48s (- 31m 12s) (8150 10%) 0.0272\n",
      "3m 49s (- 31m 11s) (8200 10%) 0.0233\n",
      "3m 51s (- 31m 11s) (8250 11%) 0.0302\n",
      "3m 52s (- 31m 11s) (8300 11%) 0.0202\n",
      "3m 54s (- 31m 10s) (8350 11%) 0.0223\n",
      "3m 55s (- 31m 10s) (8400 11%) 0.0346\n",
      "3m 57s (- 31m 8s) (8450 11%) 0.0238\n",
      "3m 58s (- 31m 7s) (8500 11%) 0.0264\n",
      "4m 0s (- 31m 6s) (8550 11%) 0.0226\n",
      "4m 1s (- 31m 6s) (8600 11%) 0.0159\n",
      "4m 3s (- 31m 5s) (8650 11%) 0.0237\n",
      "4m 4s (- 31m 4s) (8700 11%) 0.0214\n",
      "4m 6s (- 31m 4s) (8750 11%) 0.0235\n",
      "4m 7s (- 31m 3s) (8800 11%) 0.0202\n",
      "4m 9s (- 31m 2s) (8850 11%) 0.0239\n",
      "4m 10s (- 31m 1s) (8900 11%) 0.0240\n",
      "4m 12s (- 31m 0s) (8950 11%) 0.0243\n",
      "4m 13s (- 31m 0s) (9000 12%) 0.0395\n",
      "4m 15s (- 31m 0s) (9050 12%) 0.0252\n",
      "4m 16s (- 30m 59s) (9100 12%) 0.0233\n",
      "4m 18s (- 30m 59s) (9150 12%) 0.0297\n",
      "4m 19s (- 30m 58s) (9200 12%) 0.0407\n",
      "4m 21s (- 30m 57s) (9250 12%) 0.0248\n",
      "4m 22s (- 30m 57s) (9300 12%) 0.0350\n",
      "4m 24s (- 30m 56s) (9350 12%) 0.0318\n",
      "4m 25s (- 30m 55s) (9400 12%) 0.0286\n",
      "4m 27s (- 30m 54s) (9450 12%) 0.0215\n",
      "4m 28s (- 30m 54s) (9500 12%) 0.0096\n",
      "4m 30s (- 30m 54s) (9550 12%) 0.0328\n",
      "4m 32s (- 30m 53s) (9600 12%) 0.0193\n",
      "4m 33s (- 30m 52s) (9650 12%) 0.0208\n",
      "4m 35s (- 30m 52s) (9700 12%) 0.0342\n",
      "4m 36s (- 30m 51s) (9750 13%) 0.0558\n",
      "4m 38s (- 30m 50s) (9800 13%) 0.0356\n",
      "4m 39s (- 30m 50s) (9850 13%) 0.0389\n",
      "4m 41s (- 30m 49s) (9900 13%) 0.0259\n",
      "4m 42s (- 30m 48s) (9950 13%) 0.0230\n",
      "4m 44s (- 30m 46s) (10000 13%) 0.0238\n",
      "4m 45s (- 30m 46s) (10050 13%) 0.0357\n",
      "4m 47s (- 30m 45s) (10100 13%) 0.0240\n",
      "4m 48s (- 30m 44s) (10150 13%) 0.0278\n",
      "4m 50s (- 30m 43s) (10200 13%) 0.0247\n",
      "4m 51s (- 30m 43s) (10250 13%) 0.0244\n",
      "4m 53s (- 30m 42s) (10300 13%) 0.0175\n",
      "4m 54s (- 30m 41s) (10350 13%) 0.0355\n",
      "4m 56s (- 30m 41s) (10400 13%) 0.0312\n",
      "4m 57s (- 30m 40s) (10450 13%) 0.0175\n",
      "4m 59s (- 30m 39s) (10500 14%) 0.0278\n",
      "5m 0s (- 30m 38s) (10550 14%) 0.0140\n",
      "5m 2s (- 30m 36s) (10600 14%) 0.0247\n",
      "5m 3s (- 30m 35s) (10650 14%) 0.0161\n",
      "5m 5s (- 30m 34s) (10700 14%) 0.0446\n",
      "5m 6s (- 30m 33s) (10750 14%) 0.0252\n",
      "5m 8s (- 30m 32s) (10800 14%) 0.0263\n",
      "5m 9s (- 30m 31s) (10850 14%) 0.0222\n",
      "5m 11s (- 30m 31s) (10900 14%) 0.0167\n",
      "5m 12s (- 30m 29s) (10950 14%) 0.0203\n",
      "5m 14s (- 30m 28s) (11000 14%) 0.0236\n",
      "5m 15s (- 30m 27s) (11050 14%) 0.0300\n",
      "5m 17s (- 30m 27s) (11100 14%) 0.0261\n",
      "5m 18s (- 30m 25s) (11150 14%) 0.0088\n",
      "5m 20s (- 30m 24s) (11200 14%) 0.0188\n",
      "5m 21s (- 30m 23s) (11250 15%) 0.0181\n",
      "5m 23s (- 30m 22s) (11300 15%) 0.0158\n",
      "5m 24s (- 30m 21s) (11350 15%) 0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5m 26s (- 30m 20s) (11400 15%) 0.0238\n",
      "5m 27s (- 30m 20s) (11450 15%) 0.0264\n",
      "5m 29s (- 30m 18s) (11500 15%) 0.0155\n",
      "5m 30s (- 30m 17s) (11550 15%) 0.0138\n",
      "5m 32s (- 30m 17s) (11600 15%) 0.0240\n",
      "5m 33s (- 30m 16s) (11650 15%) 0.0451\n",
      "5m 35s (- 30m 14s) (11700 15%) 0.0284\n",
      "5m 36s (- 30m 13s) (11750 15%) 0.0256\n",
      "5m 38s (- 30m 12s) (11800 15%) 0.0151\n",
      "5m 39s (- 30m 11s) (11850 15%) 0.0221\n",
      "5m 41s (- 30m 10s) (11900 15%) 0.0205\n",
      "5m 42s (- 30m 9s) (11950 15%) 0.0316\n",
      "5m 44s (- 30m 8s) (12000 16%) 0.0245\n",
      "5m 45s (- 30m 7s) (12050 16%) 0.0181\n",
      "5m 47s (- 30m 5s) (12100 16%) 0.0160\n",
      "5m 48s (- 30m 4s) (12150 16%) 0.0298\n",
      "5m 50s (- 30m 3s) (12200 16%) 0.1367\n",
      "5m 51s (- 30m 2s) (12250 16%) 0.0391\n",
      "5m 53s (- 30m 1s) (12300 16%) 0.0140\n",
      "5m 54s (- 30m 0s) (12350 16%) 0.0213\n",
      "5m 56s (- 29m 59s) (12400 16%) 0.0136\n",
      "5m 57s (- 29m 58s) (12450 16%) 0.0256\n",
      "5m 59s (- 29m 57s) (12500 16%) 0.0306\n",
      "6m 1s (- 29m 57s) (12550 16%) 0.0224\n",
      "6m 2s (- 29m 56s) (12600 16%) 0.0158\n",
      "6m 4s (- 29m 55s) (12650 16%) 0.0215\n",
      "6m 5s (- 29m 54s) (12700 16%) 0.0130\n",
      "6m 7s (- 29m 53s) (12750 17%) 0.0187\n",
      "6m 8s (- 29m 52s) (12800 17%) 0.0145\n",
      "6m 10s (- 29m 51s) (12850 17%) 0.0108\n",
      "6m 11s (- 29m 49s) (12900 17%) 0.0172\n",
      "6m 13s (- 29m 48s) (12950 17%) 0.0310\n",
      "6m 14s (- 29m 47s) (13000 17%) 0.0216\n",
      "6m 16s (- 29m 45s) (13050 17%) 0.0243\n",
      "6m 17s (- 29m 44s) (13100 17%) 0.0340\n",
      "6m 19s (- 29m 43s) (13150 17%) 0.0352\n",
      "6m 20s (- 29m 42s) (13200 17%) 0.0178\n",
      "6m 22s (- 29m 41s) (13250 17%) 0.0255\n",
      "6m 23s (- 29m 40s) (13300 17%) 0.0291\n",
      "6m 25s (- 29m 39s) (13350 17%) 0.0450\n",
      "6m 26s (- 29m 38s) (13400 17%) 0.0100\n",
      "6m 28s (- 29m 37s) (13450 17%) 0.0153\n",
      "6m 29s (- 29m 36s) (13500 18%) 0.0198\n",
      "6m 31s (- 29m 35s) (13550 18%) 0.0199\n",
      "6m 33s (- 29m 34s) (13600 18%) 0.0174\n",
      "6m 34s (- 29m 33s) (13650 18%) 0.0296\n",
      "6m 36s (- 29m 32s) (13700 18%) 0.0323\n",
      "6m 37s (- 29m 31s) (13750 18%) 0.0164\n",
      "6m 39s (- 29m 30s) (13800 18%) 0.0230\n",
      "6m 40s (- 29m 29s) (13850 18%) 0.0148\n",
      "6m 42s (- 29m 28s) (13900 18%) 0.0229\n",
      "6m 43s (- 29m 26s) (13950 18%) 0.0204\n",
      "6m 45s (- 29m 25s) (14000 18%) 0.0158\n",
      "6m 46s (- 29m 23s) (14050 18%) 0.0172\n",
      "6m 48s (- 29m 22s) (14100 18%) 0.0262\n",
      "6m 49s (- 29m 21s) (14150 18%) 0.0294\n",
      "6m 51s (- 29m 20s) (14200 18%) 0.0194\n",
      "6m 52s (- 29m 19s) (14250 19%) 0.0173\n",
      "6m 54s (- 29m 17s) (14300 19%) 0.0298\n",
      "6m 55s (- 29m 16s) (14350 19%) 0.0177\n",
      "6m 57s (- 29m 15s) (14400 19%) 0.0165\n",
      "6m 58s (- 29m 14s) (14450 19%) 0.0175\n",
      "7m 0s (- 29m 13s) (14500 19%) 0.0236\n",
      "7m 1s (- 29m 12s) (14550 19%) 0.0133\n",
      "7m 3s (- 29m 11s) (14600 19%) 0.0134\n",
      "7m 4s (- 29m 10s) (14650 19%) 0.0242\n",
      "7m 6s (- 29m 9s) (14700 19%) 0.0198\n",
      "7m 8s (- 29m 8s) (14750 19%) 0.0157\n",
      "7m 9s (- 29m 7s) (14800 19%) 0.0243\n",
      "7m 11s (- 29m 6s) (14850 19%) 0.0170\n",
      "7m 12s (- 29m 4s) (14900 19%) 0.0256\n",
      "7m 14s (- 29m 3s) (14950 19%) 0.0169\n",
      "7m 15s (- 29m 3s) (15000 20%) 0.0177\n",
      "7m 17s (- 29m 1s) (15050 20%) 0.0190\n",
      "7m 18s (- 29m 0s) (15100 20%) 0.0240\n",
      "7m 20s (- 28m 58s) (15150 20%) 0.0101\n",
      "7m 21s (- 28m 57s) (15200 20%) 0.0166\n",
      "7m 23s (- 28m 56s) (15250 20%) 0.0099\n",
      "7m 24s (- 28m 54s) (15300 20%) 0.0132\n",
      "7m 26s (- 28m 53s) (15350 20%) 0.0233\n",
      "7m 27s (- 28m 52s) (15400 20%) 0.0116\n",
      "7m 29s (- 28m 51s) (15450 20%) 0.0118\n",
      "7m 30s (- 28m 50s) (15500 20%) 0.0121\n",
      "7m 32s (- 28m 49s) (15550 20%) 0.0133\n",
      "7m 33s (- 28m 47s) (15600 20%) 0.0136\n",
      "7m 35s (- 28m 46s) (15650 20%) 0.0258\n",
      "7m 36s (- 28m 45s) (15700 20%) 0.0315\n",
      "7m 38s (- 28m 44s) (15750 21%) 0.0158\n",
      "7m 39s (- 28m 42s) (15800 21%) 0.0232\n",
      "7m 41s (- 28m 40s) (15850 21%) 0.0193\n",
      "7m 42s (- 28m 40s) (15900 21%) 0.0204\n",
      "7m 44s (- 28m 39s) (15950 21%) 0.0246\n",
      "7m 45s (- 28m 38s) (16000 21%) 0.0144\n",
      "7m 47s (- 28m 36s) (16050 21%) 0.0185\n",
      "7m 48s (- 28m 35s) (16100 21%) 0.0291\n",
      "7m 50s (- 28m 34s) (16150 21%) 0.0183\n",
      "7m 51s (- 28m 32s) (16200 21%) 0.0118\n",
      "7m 53s (- 28m 31s) (16250 21%) 0.0192\n",
      "7m 54s (- 28m 30s) (16300 21%) 0.0117\n",
      "7m 56s (- 28m 28s) (16350 21%) 0.0199\n",
      "7m 57s (- 28m 27s) (16400 21%) 0.0430\n",
      "7m 59s (- 28m 26s) (16450 21%) 0.0287\n",
      "8m 0s (- 28m 25s) (16500 22%) 0.0189\n",
      "8m 2s (- 28m 23s) (16550 22%) 0.0131\n",
      "8m 3s (- 28m 21s) (16600 22%) 0.0112\n",
      "8m 5s (- 28m 20s) (16650 22%) 0.0219\n",
      "8m 6s (- 28m 18s) (16700 22%) 0.0163\n",
      "8m 8s (- 28m 17s) (16750 22%) 0.0197\n",
      "8m 9s (- 28m 16s) (16800 22%) 0.0071\n",
      "8m 11s (- 28m 14s) (16850 22%) 0.0194\n",
      "8m 12s (- 28m 13s) (16900 22%) 0.0105\n",
      "8m 14s (- 28m 12s) (16950 22%) 0.0192\n",
      "8m 15s (- 28m 11s) (17000 22%) 0.0141\n",
      "8m 17s (- 28m 9s) (17050 22%) 0.0265\n",
      "8m 18s (- 28m 8s) (17100 22%) 0.0180\n",
      "8m 20s (- 28m 6s) (17150 22%) 0.0213\n",
      "8m 21s (- 28m 6s) (17200 22%) 0.0258\n",
      "8m 23s (- 28m 4s) (17250 23%) 0.0301\n",
      "8m 24s (- 28m 3s) (17300 23%) 0.0135\n",
      "8m 26s (- 28m 2s) (17350 23%) 0.0204\n",
      "8m 27s (- 28m 1s) (17400 23%) 0.0275\n",
      "8m 29s (- 27m 59s) (17450 23%) 0.0175\n",
      "8m 30s (- 27m 58s) (17500 23%) 0.0193\n",
      "8m 32s (- 27m 57s) (17550 23%) 0.0260\n",
      "8m 33s (- 27m 56s) (17600 23%) 0.0299\n",
      "8m 35s (- 27m 54s) (17650 23%) 0.0248\n",
      "8m 37s (- 27m 53s) (17700 23%) 0.0247\n",
      "8m 38s (- 27m 52s) (17750 23%) 0.0320\n",
      "8m 40s (- 27m 51s) (17800 23%) 0.0186\n",
      "8m 41s (- 27m 50s) (17850 23%) 0.0118\n",
      "8m 43s (- 27m 48s) (17900 23%) 0.0111\n",
      "8m 44s (- 27m 47s) (17950 23%) 0.0092\n",
      "8m 46s (- 27m 46s) (18000 24%) 0.0234\n",
      "8m 47s (- 27m 45s) (18050 24%) 0.0218\n",
      "8m 49s (- 27m 43s) (18100 24%) 0.0117\n",
      "8m 50s (- 27m 42s) (18150 24%) 0.0155\n",
      "8m 52s (- 27m 41s) (18200 24%) 0.0221\n",
      "8m 53s (- 27m 40s) (18250 24%) 0.0248\n",
      "8m 55s (- 27m 38s) (18300 24%) 0.0116\n",
      "8m 56s (- 27m 37s) (18350 24%) 0.0205\n",
      "8m 58s (- 27m 36s) (18400 24%) 0.0244\n",
      "8m 59s (- 27m 34s) (18450 24%) 0.0130\n",
      "9m 1s (- 27m 33s) (18500 24%) 0.0177\n",
      "9m 2s (- 27m 32s) (18550 24%) 0.0119\n",
      "9m 4s (- 27m 30s) (18600 24%) 0.0178\n",
      "9m 5s (- 27m 29s) (18650 24%) 0.0126\n",
      "9m 7s (- 27m 27s) (18700 24%) 0.0092\n",
      "9m 8s (- 27m 26s) (18750 25%) 0.0149\n",
      "9m 10s (- 27m 24s) (18800 25%) 0.0149\n",
      "9m 11s (- 27m 23s) (18850 25%) 0.0166\n",
      "9m 13s (- 27m 22s) (18900 25%) 0.0130\n",
      "9m 14s (- 27m 21s) (18950 25%) 0.0093\n",
      "9m 16s (- 27m 20s) (19000 25%) 0.0359\n",
      "9m 17s (- 27m 18s) (19050 25%) 0.0121\n",
      "9m 19s (- 27m 17s) (19100 25%) 0.0115\n",
      "9m 20s (- 27m 16s) (19150 25%) 0.0102\n",
      "9m 22s (- 27m 14s) (19200 25%) 0.0145\n",
      "9m 24s (- 27m 13s) (19250 25%) 0.0215\n",
      "9m 25s (- 27m 12s) (19300 25%) 0.0156\n",
      "9m 26s (- 27m 10s) (19350 25%) 0.0141\n",
      "9m 28s (- 27m 8s) (19400 25%) 0.0096\n",
      "9m 29s (- 27m 7s) (19450 25%) 0.0192\n",
      "9m 31s (- 27m 6s) (19500 26%) 0.0328\n",
      "9m 32s (- 27m 4s) (19550 26%) 0.0140\n",
      "9m 34s (- 27m 3s) (19600 26%) 0.0208\n",
      "9m 36s (- 27m 2s) (19650 26%) 0.0162\n",
      "9m 37s (- 27m 1s) (19700 26%) 0.0114\n",
      "9m 39s (- 26m 59s) (19750 26%) 0.0092\n",
      "9m 40s (- 26m 58s) (19800 26%) 0.0151\n",
      "9m 42s (- 26m 57s) (19850 26%) 0.0085\n",
      "9m 43s (- 26m 55s) (19900 26%) 0.0123\n",
      "9m 45s (- 26m 54s) (19950 26%) 0.0119\n",
      "9m 46s (- 26m 53s) (20000 26%) 0.0183\n",
      "9m 48s (- 26m 51s) (20050 26%) 0.0125\n",
      "9m 49s (- 26m 50s) (20100 26%) 0.0140\n",
      "9m 51s (- 26m 49s) (20150 26%) 0.0259\n",
      "9m 52s (- 26m 48s) (20200 26%) 0.0188\n",
      "9m 54s (- 26m 46s) (20250 27%) 0.0057\n",
      "9m 55s (- 26m 45s) (20300 27%) 0.0131\n",
      "9m 57s (- 26m 44s) (20350 27%) 0.0187\n",
      "9m 58s (- 26m 42s) (20400 27%) 0.0147\n",
      "10m 0s (- 26m 41s) (20450 27%) 0.0155\n",
      "10m 2s (- 26m 40s) (20500 27%) 0.0177\n",
      "10m 3s (- 26m 38s) (20550 27%) 0.0106\n",
      "10m 4s (- 26m 37s) (20600 27%) 0.0149\n",
      "10m 6s (- 26m 35s) (20650 27%) 0.0160\n",
      "10m 7s (- 26m 34s) (20700 27%) 0.0200\n",
      "10m 9s (- 26m 33s) (20750 27%) 0.0166\n",
      "10m 10s (- 26m 32s) (20800 27%) 0.0129\n",
      "10m 12s (- 26m 30s) (20850 27%) 0.0090\n",
      "10m 14s (- 26m 29s) (20900 27%) 0.0103\n",
      "10m 15s (- 26m 28s) (20950 27%) 0.0285\n",
      "10m 17s (- 26m 27s) (21000 28%) 0.0258\n",
      "10m 18s (- 26m 25s) (21050 28%) 0.0143\n",
      "10m 20s (- 26m 24s) (21100 28%) 0.0100\n",
      "10m 21s (- 26m 22s) (21150 28%) 0.0118\n",
      "10m 23s (- 26m 21s) (21200 28%) 0.0215\n",
      "10m 24s (- 26m 19s) (21250 28%) 0.0162\n",
      "10m 26s (- 26m 18s) (21300 28%) 0.0193\n",
      "10m 27s (- 26m 16s) (21350 28%) 0.0199\n",
      "10m 29s (- 26m 15s) (21400 28%) 0.0143\n",
      "10m 30s (- 26m 14s) (21450 28%) 0.0184\n",
      "10m 32s (- 26m 12s) (21500 28%) 0.0115\n",
      "10m 33s (- 26m 11s) (21550 28%) 0.0216\n",
      "10m 35s (- 26m 10s) (21600 28%) 0.0116\n",
      "10m 36s (- 26m 8s) (21650 28%) 0.0303\n",
      "10m 38s (- 26m 7s) (21700 28%) 0.0146\n",
      "10m 39s (- 26m 6s) (21750 28%) 0.0087\n",
      "10m 41s (- 26m 4s) (21800 29%) 0.0109\n",
      "10m 42s (- 26m 3s) (21850 29%) 0.0069\n",
      "10m 44s (- 26m 1s) (21900 29%) 0.0065\n",
      "10m 45s (- 26m 0s) (21950 29%) 0.0185\n",
      "10m 47s (- 25m 58s) (22000 29%) 0.0214\n",
      "10m 48s (- 25m 57s) (22050 29%) 0.0116\n",
      "10m 50s (- 25m 56s) (22100 29%) 0.0099\n",
      "10m 51s (- 25m 54s) (22150 29%) 0.0121\n",
      "10m 53s (- 25m 53s) (22200 29%) 0.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 54s (- 25m 52s) (22250 29%) 0.0236\n",
      "10m 56s (- 25m 51s) (22300 29%) 0.0161\n",
      "10m 57s (- 25m 49s) (22350 29%) 0.0119\n",
      "10m 59s (- 25m 48s) (22400 29%) 0.0122\n",
      "11m 0s (- 25m 47s) (22450 29%) 0.0249\n",
      "11m 2s (- 25m 45s) (22500 30%) 0.0118\n",
      "11m 3s (- 25m 44s) (22550 30%) 0.0111\n",
      "11m 5s (- 25m 43s) (22600 30%) 0.0075\n",
      "11m 7s (- 25m 41s) (22650 30%) 0.0106\n",
      "11m 8s (- 25m 40s) (22700 30%) 0.0364\n",
      "11m 10s (- 25m 38s) (22750 30%) 0.0150\n",
      "11m 11s (- 25m 37s) (22800 30%) 0.0114\n",
      "11m 13s (- 25m 36s) (22850 30%) 0.0169\n",
      "11m 14s (- 25m 34s) (22900 30%) 0.0146\n",
      "11m 16s (- 25m 33s) (22950 30%) 0.0116\n",
      "11m 17s (- 25m 31s) (23000 30%) 0.0090\n",
      "11m 19s (- 25m 30s) (23050 30%) 0.0130\n",
      "11m 20s (- 25m 29s) (23100 30%) 0.0117\n",
      "11m 22s (- 25m 28s) (23150 30%) 0.0128\n",
      "11m 23s (- 25m 27s) (23200 30%) 0.0092\n",
      "11m 25s (- 25m 25s) (23250 31%) 0.0102\n",
      "11m 26s (- 25m 24s) (23300 31%) 0.0206\n",
      "11m 28s (- 25m 22s) (23350 31%) 0.0272\n",
      "11m 29s (- 25m 21s) (23400 31%) 0.0230\n",
      "11m 31s (- 25m 20s) (23450 31%) 0.0237\n",
      "11m 33s (- 25m 18s) (23500 31%) 0.0124\n",
      "11m 34s (- 25m 17s) (23550 31%) 0.0124\n",
      "11m 36s (- 25m 15s) (23600 31%) 0.0119\n",
      "11m 37s (- 25m 14s) (23650 31%) 0.0204\n",
      "11m 39s (- 25m 13s) (23700 31%) 0.0164\n",
      "11m 40s (- 25m 12s) (23750 31%) 0.0180\n",
      "11m 42s (- 25m 10s) (23800 31%) 0.0097\n",
      "11m 43s (- 25m 9s) (23850 31%) 0.0217\n",
      "11m 45s (- 25m 7s) (23900 31%) 0.0095\n",
      "11m 46s (- 25m 5s) (23950 31%) 0.0189\n",
      "11m 47s (- 25m 4s) (24000 32%) 0.0060\n",
      "11m 49s (- 25m 2s) (24050 32%) 0.0165\n",
      "11m 50s (- 25m 1s) (24100 32%) 0.0070\n",
      "11m 52s (- 24m 59s) (24150 32%) 0.0105\n",
      "11m 53s (- 24m 58s) (24200 32%) 0.0090\n",
      "11m 55s (- 24m 56s) (24250 32%) 0.0190\n",
      "11m 56s (- 24m 55s) (24300 32%) 0.0105\n",
      "11m 58s (- 24m 53s) (24350 32%) 0.0084\n",
      "11m 59s (- 24m 52s) (24400 32%) 0.0094\n",
      "12m 1s (- 24m 51s) (24450 32%) 0.0103\n",
      "12m 2s (- 24m 49s) (24500 32%) 0.0244\n",
      "12m 4s (- 24m 48s) (24550 32%) 0.0144\n",
      "12m 5s (- 24m 47s) (24600 32%) 0.0071\n",
      "12m 7s (- 24m 45s) (24650 32%) 0.0135\n",
      "12m 8s (- 24m 44s) (24700 32%) 0.0113\n",
      "12m 10s (- 24m 43s) (24750 33%) 0.0140\n",
      "12m 11s (- 24m 41s) (24800 33%) 0.0062\n",
      "12m 13s (- 24m 40s) (24850 33%) 0.0147\n",
      "12m 15s (- 24m 38s) (24900 33%) 0.0111\n",
      "12m 16s (- 24m 37s) (24950 33%) 0.0148\n",
      "12m 18s (- 24m 36s) (25000 33%) 0.0111\n",
      "12m 19s (- 24m 34s) (25050 33%) 0.0082\n",
      "12m 21s (- 24m 33s) (25100 33%) 0.0180\n",
      "12m 22s (- 24m 32s) (25150 33%) 0.0093\n",
      "12m 24s (- 24m 30s) (25200 33%) 0.0065\n",
      "12m 25s (- 24m 29s) (25250 33%) 0.0265\n",
      "12m 27s (- 24m 28s) (25300 33%) 0.0234\n",
      "12m 28s (- 24m 26s) (25350 33%) 0.0210\n",
      "12m 30s (- 24m 25s) (25400 33%) 0.0193\n",
      "12m 32s (- 24m 24s) (25450 33%) 0.0088\n",
      "12m 33s (- 24m 22s) (25500 34%) 0.0131\n",
      "12m 35s (- 24m 21s) (25550 34%) 0.0163\n",
      "12m 36s (- 24m 19s) (25600 34%) 0.0070\n",
      "12m 37s (- 24m 18s) (25650 34%) 0.0153\n",
      "12m 39s (- 24m 16s) (25700 34%) 0.0091\n",
      "12m 40s (- 24m 15s) (25750 34%) 0.0114\n",
      "12m 42s (- 24m 13s) (25800 34%) 0.0261\n",
      "12m 43s (- 24m 12s) (25850 34%) 0.0139\n",
      "12m 45s (- 24m 10s) (25900 34%) 0.0160\n",
      "12m 46s (- 24m 9s) (25950 34%) 0.0116\n",
      "12m 48s (- 24m 7s) (26000 34%) 0.0234\n",
      "12m 49s (- 24m 6s) (26050 34%) 0.0143\n",
      "12m 51s (- 24m 5s) (26100 34%) 0.0077\n",
      "12m 52s (- 24m 3s) (26150 34%) 0.0192\n",
      "12m 54s (- 24m 2s) (26200 34%) 0.0141\n",
      "12m 55s (- 24m 0s) (26250 35%) 0.0207\n",
      "12m 57s (- 23m 59s) (26300 35%) 0.0083\n",
      "12m 59s (- 23m 58s) (26350 35%) 0.0263\n",
      "13m 0s (- 23m 56s) (26400 35%) 0.0136\n",
      "13m 1s (- 23m 55s) (26450 35%) 0.0089\n",
      "13m 3s (- 23m 53s) (26500 35%) 0.0085\n",
      "13m 4s (- 23m 52s) (26550 35%) 0.0103\n",
      "13m 6s (- 23m 50s) (26600 35%) 0.0066\n",
      "13m 7s (- 23m 49s) (26650 35%) 0.0064\n",
      "13m 9s (- 23m 47s) (26700 35%) 0.0086\n",
      "13m 10s (- 23m 46s) (26750 35%) 0.0141\n",
      "13m 12s (- 23m 44s) (26800 35%) 0.0067\n",
      "13m 13s (- 23m 43s) (26850 35%) 0.0068\n",
      "13m 15s (- 23m 41s) (26900 35%) 0.0073\n",
      "13m 16s (- 23m 40s) (26950 35%) 0.0152\n",
      "13m 18s (- 23m 38s) (27000 36%) 0.0214\n",
      "13m 19s (- 23m 37s) (27050 36%) 0.0135\n",
      "13m 21s (- 23m 36s) (27100 36%) 0.0144\n",
      "13m 22s (- 23m 34s) (27150 36%) 0.0149\n",
      "13m 24s (- 23m 33s) (27200 36%) 0.0092\n",
      "13m 25s (- 23m 31s) (27250 36%) 0.0078\n",
      "13m 27s (- 23m 30s) (27300 36%) 0.0099\n",
      "13m 28s (- 23m 28s) (27350 36%) 0.0193\n",
      "13m 30s (- 23m 27s) (27400 36%) 0.0176\n",
      "13m 31s (- 23m 25s) (27450 36%) 0.0294\n",
      "13m 32s (- 23m 24s) (27500 36%) 0.0117\n",
      "13m 34s (- 23m 22s) (27550 36%) 0.0173\n",
      "13m 35s (- 23m 21s) (27600 36%) 0.0186\n",
      "13m 37s (- 23m 19s) (27650 36%) 0.0096\n",
      "13m 38s (- 23m 18s) (27700 36%) 0.0091\n",
      "13m 40s (- 23m 16s) (27750 37%) 0.0113\n",
      "13m 41s (- 23m 15s) (27800 37%) 0.0174\n",
      "13m 43s (- 23m 14s) (27850 37%) 0.0121\n",
      "13m 44s (- 23m 12s) (27900 37%) 0.0110\n",
      "13m 46s (- 23m 11s) (27950 37%) 0.0059\n",
      "13m 48s (- 23m 9s) (28000 37%) 0.0205\n",
      "13m 49s (- 23m 8s) (28050 37%) 0.0102\n",
      "13m 51s (- 23m 7s) (28100 37%) 0.0161\n",
      "13m 52s (- 23m 5s) (28150 37%) 0.0121\n",
      "13m 54s (- 23m 4s) (28200 37%) 0.0095\n",
      "13m 55s (- 23m 2s) (28250 37%) 0.0148\n",
      "13m 57s (- 23m 1s) (28300 37%) 0.0216\n",
      "13m 58s (- 22m 59s) (28350 37%) 0.0054\n",
      "14m 0s (- 22m 58s) (28400 37%) 0.0124\n",
      "14m 1s (- 22m 56s) (28450 37%) 0.0137\n",
      "14m 3s (- 22m 55s) (28500 38%) 0.0074\n",
      "14m 4s (- 22m 54s) (28550 38%) 0.0126\n",
      "14m 6s (- 22m 52s) (28600 38%) 0.0068\n",
      "14m 7s (- 22m 51s) (28650 38%) 0.0083\n",
      "14m 9s (- 22m 49s) (28700 38%) 0.0081\n",
      "14m 10s (- 22m 48s) (28750 38%) 0.0112\n",
      "14m 12s (- 22m 47s) (28800 38%) 0.0088\n",
      "14m 13s (- 22m 45s) (28850 38%) 0.0175\n",
      "14m 15s (- 22m 44s) (28900 38%) 0.0100\n",
      "14m 16s (- 22m 43s) (28950 38%) 0.0231\n",
      "14m 18s (- 22m 41s) (29000 38%) 0.0198\n",
      "14m 19s (- 22m 40s) (29050 38%) 0.0143\n",
      "14m 21s (- 22m 38s) (29100 38%) 0.0383\n",
      "14m 22s (- 22m 37s) (29150 38%) 0.0091\n",
      "14m 24s (- 22m 35s) (29200 38%) 0.0118\n",
      "14m 25s (- 22m 34s) (29250 39%) 0.0125\n",
      "14m 27s (- 22m 32s) (29300 39%) 0.0093\n",
      "14m 28s (- 22m 31s) (29350 39%) 0.0103\n",
      "14m 30s (- 22m 29s) (29400 39%) 0.0100\n",
      "14m 31s (- 22m 28s) (29450 39%) 0.0206\n",
      "14m 33s (- 22m 27s) (29500 39%) 0.0067\n",
      "14m 34s (- 22m 25s) (29550 39%) 0.0103\n",
      "14m 36s (- 22m 23s) (29600 39%) 0.0236\n",
      "14m 37s (- 22m 22s) (29650 39%) 0.0123\n",
      "14m 39s (- 22m 21s) (29700 39%) 0.0121\n",
      "14m 40s (- 22m 19s) (29750 39%) 0.0056\n",
      "14m 42s (- 22m 18s) (29800 39%) 0.0060\n",
      "14m 43s (- 22m 16s) (29850 39%) 0.0115\n",
      "14m 45s (- 22m 15s) (29900 39%) 0.0090\n",
      "14m 46s (- 22m 14s) (29950 39%) 0.0202\n",
      "14m 48s (- 22m 12s) (30000 40%) 0.0137\n",
      "14m 49s (- 22m 11s) (30050 40%) 0.0131\n",
      "14m 51s (- 22m 9s) (30100 40%) 0.0227\n",
      "14m 52s (- 22m 8s) (30150 40%) 0.0046\n",
      "14m 54s (- 22m 6s) (30200 40%) 0.0129\n",
      "14m 55s (- 22m 5s) (30250 40%) 0.0093\n",
      "14m 57s (- 22m 3s) (30300 40%) 0.0102\n",
      "14m 58s (- 22m 2s) (30350 40%) 0.0128\n",
      "15m 0s (- 22m 1s) (30400 40%) 0.0075\n",
      "15m 2s (- 21m 59s) (30450 40%) 0.0332\n",
      "15m 3s (- 21m 58s) (30500 40%) 0.0087\n",
      "15m 5s (- 21m 57s) (30550 40%) 0.0076\n",
      "15m 6s (- 21m 55s) (30600 40%) 0.0092\n",
      "15m 8s (- 21m 54s) (30650 40%) 0.0109\n",
      "15m 9s (- 21m 52s) (30700 40%) 0.0080\n",
      "15m 11s (- 21m 51s) (30750 41%) 0.0093\n",
      "15m 12s (- 21m 49s) (30800 41%) 0.0102\n",
      "15m 14s (- 21m 48s) (30850 41%) 0.0089\n",
      "15m 15s (- 21m 46s) (30900 41%) 0.0116\n",
      "15m 16s (- 21m 45s) (30950 41%) 0.0114\n",
      "15m 18s (- 21m 43s) (31000 41%) 0.0095\n",
      "15m 19s (- 21m 42s) (31050 41%) 0.0161\n",
      "15m 21s (- 21m 40s) (31100 41%) 0.0112\n",
      "15m 22s (- 21m 39s) (31150 41%) 0.0105\n",
      "15m 24s (- 21m 37s) (31200 41%) 0.0051\n",
      "15m 25s (- 21m 36s) (31250 41%) 0.0109\n",
      "15m 27s (- 21m 34s) (31300 41%) 0.0065\n",
      "15m 28s (- 21m 33s) (31350 41%) 0.0072\n",
      "15m 30s (- 21m 31s) (31400 41%) 0.0119\n",
      "15m 31s (- 21m 30s) (31450 41%) 0.0091\n",
      "15m 33s (- 21m 29s) (31500 42%) 0.0109\n",
      "15m 34s (- 21m 27s) (31550 42%) 0.0062\n",
      "15m 36s (- 21m 26s) (31600 42%) 0.0123\n",
      "15m 38s (- 21m 24s) (31650 42%) 0.0147\n",
      "15m 39s (- 21m 23s) (31700 42%) 0.0154\n",
      "15m 41s (- 21m 21s) (31750 42%) 0.0098\n",
      "15m 42s (- 21m 20s) (31800 42%) 0.0070\n",
      "15m 43s (- 21m 18s) (31850 42%) 0.0149\n",
      "15m 45s (- 21m 17s) (31900 42%) 0.0131\n",
      "15m 46s (- 21m 15s) (31950 42%) 0.0050\n",
      "15m 48s (- 21m 14s) (32000 42%) 0.0076\n",
      "15m 49s (- 21m 13s) (32050 42%) 0.0074\n",
      "15m 51s (- 21m 11s) (32100 42%) 0.0066\n",
      "15m 53s (- 21m 10s) (32150 42%) 0.0220\n",
      "15m 54s (- 21m 8s) (32200 42%) 0.0138\n",
      "15m 56s (- 21m 7s) (32250 43%) 0.0089\n",
      "15m 57s (- 21m 5s) (32300 43%) 0.0038\n",
      "15m 59s (- 21m 4s) (32350 43%) 0.0100\n",
      "16m 0s (- 21m 2s) (32400 43%) 0.0098\n",
      "16m 2s (- 21m 1s) (32450 43%) 0.0134\n",
      "16m 3s (- 21m 0s) (32500 43%) 0.0096\n",
      "16m 5s (- 20m 58s) (32550 43%) 0.0078\n",
      "16m 6s (- 20m 57s) (32600 43%) 0.0097\n",
      "16m 7s (- 20m 55s) (32650 43%) 0.0059\n",
      "16m 9s (- 20m 54s) (32700 43%) 0.0128\n",
      "16m 10s (- 20m 52s) (32750 43%) 0.0044\n",
      "16m 12s (- 20m 51s) (32800 43%) 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16m 14s (- 20m 49s) (32850 43%) 0.0136\n",
      "16m 15s (- 20m 48s) (32900 43%) 0.0067\n",
      "16m 17s (- 20m 47s) (32950 43%) 0.0088\n",
      "16m 18s (- 20m 45s) (33000 44%) 0.0054\n",
      "16m 20s (- 20m 44s) (33050 44%) 0.0066\n",
      "16m 21s (- 20m 42s) (33100 44%) 0.0137\n",
      "16m 23s (- 20m 40s) (33150 44%) 0.0054\n",
      "16m 24s (- 20m 39s) (33200 44%) 0.0090\n",
      "16m 25s (- 20m 37s) (33250 44%) 0.0066\n",
      "16m 27s (- 20m 36s) (33300 44%) 0.0162\n",
      "16m 29s (- 20m 35s) (33350 44%) 0.0052\n",
      "16m 30s (- 20m 33s) (33400 44%) 0.0082\n",
      "16m 31s (- 20m 32s) (33450 44%) 0.0152\n",
      "16m 33s (- 20m 30s) (33500 44%) 0.0161\n",
      "16m 35s (- 20m 29s) (33550 44%) 0.0192\n",
      "16m 36s (- 20m 27s) (33600 44%) 0.0056\n",
      "16m 38s (- 20m 26s) (33650 44%) 0.0055\n",
      "16m 39s (- 20m 24s) (33700 44%) 0.0070\n",
      "16m 40s (- 20m 23s) (33750 45%) 0.0045\n",
      "16m 42s (- 20m 21s) (33800 45%) 0.0052\n",
      "16m 43s (- 20m 20s) (33850 45%) 0.0100\n",
      "16m 45s (- 20m 18s) (33900 45%) 0.0148\n",
      "16m 46s (- 20m 17s) (33950 45%) 0.0227\n",
      "16m 48s (- 20m 15s) (34000 45%) 0.0091\n",
      "16m 49s (- 20m 14s) (34050 45%) 0.0107\n",
      "16m 51s (- 20m 12s) (34100 45%) 0.0079\n",
      "16m 52s (- 20m 11s) (34150 45%) 0.0055\n",
      "16m 54s (- 20m 9s) (34200 45%) 0.0056\n",
      "16m 55s (- 20m 8s) (34250 45%) 0.0077\n",
      "16m 57s (- 20m 6s) (34300 45%) 0.0066\n",
      "16m 58s (- 20m 5s) (34350 45%) 0.0036\n",
      "17m 0s (- 20m 4s) (34400 45%) 0.0070\n",
      "17m 1s (- 20m 2s) (34450 45%) 0.0069\n",
      "17m 3s (- 20m 1s) (34500 46%) 0.0055\n",
      "17m 4s (- 19m 59s) (34550 46%) 0.0051\n",
      "17m 6s (- 19m 58s) (34600 46%) 0.0086\n",
      "17m 7s (- 19m 56s) (34650 46%) 0.0046\n",
      "17m 9s (- 19m 55s) (34700 46%) 0.0064\n",
      "17m 10s (- 19m 53s) (34750 46%) 0.0176\n",
      "17m 12s (- 19m 52s) (34800 46%) 0.0109\n",
      "17m 13s (- 19m 51s) (34850 46%) 0.0036\n",
      "17m 15s (- 19m 49s) (34900 46%) 0.0084\n",
      "17m 17s (- 19m 48s) (34950 46%) 0.0136\n",
      "17m 18s (- 19m 46s) (35000 46%) 0.0124\n",
      "17m 20s (- 19m 45s) (35050 46%) 0.0128\n",
      "17m 21s (- 19m 44s) (35100 46%) 0.0116\n",
      "17m 23s (- 19m 42s) (35150 46%) 0.0071\n",
      "17m 24s (- 19m 41s) (35200 46%) 0.0165\n",
      "17m 26s (- 19m 39s) (35250 47%) 0.0047\n",
      "17m 27s (- 19m 38s) (35300 47%) 0.0068\n",
      "17m 29s (- 19m 37s) (35350 47%) 0.0080\n",
      "17m 30s (- 19m 35s) (35400 47%) 0.0064\n",
      "17m 32s (- 19m 34s) (35450 47%) 0.0105\n",
      "17m 33s (- 19m 32s) (35500 47%) 0.0121\n",
      "17m 35s (- 19m 30s) (35550 47%) 0.0035\n",
      "17m 36s (- 19m 29s) (35600 47%) 0.0078\n",
      "17m 38s (- 19m 28s) (35650 47%) 0.0112\n",
      "17m 39s (- 19m 26s) (35700 47%) 0.0045\n",
      "17m 41s (- 19m 25s) (35750 47%) 0.0113\n",
      "17m 42s (- 19m 23s) (35800 47%) 0.0057\n",
      "17m 44s (- 19m 22s) (35850 47%) 0.0068\n",
      "17m 45s (- 19m 20s) (35900 47%) 0.0057\n",
      "17m 47s (- 19m 19s) (35950 47%) 0.0079\n",
      "17m 48s (- 19m 17s) (36000 48%) 0.0075\n",
      "17m 49s (- 19m 15s) (36050 48%) 0.0090\n",
      "17m 51s (- 19m 14s) (36100 48%) 0.0078\n",
      "17m 52s (- 19m 13s) (36150 48%) 0.0062\n",
      "17m 54s (- 19m 11s) (36200 48%) 0.0073\n",
      "17m 55s (- 19m 10s) (36250 48%) 0.0060\n",
      "17m 57s (- 19m 8s) (36300 48%) 0.0100\n",
      "17m 58s (- 19m 7s) (36350 48%) 0.0085\n",
      "18m 0s (- 19m 5s) (36400 48%) 0.0039\n",
      "18m 2s (- 19m 4s) (36450 48%) 0.0188\n",
      "18m 3s (- 19m 2s) (36500 48%) 0.0159\n",
      "18m 5s (- 19m 1s) (36550 48%) 0.0103\n",
      "18m 6s (- 18m 59s) (36600 48%) 0.0083\n",
      "18m 7s (- 18m 58s) (36650 48%) 0.0051\n",
      "18m 9s (- 18m 56s) (36700 48%) 0.0096\n",
      "18m 10s (- 18m 55s) (36750 49%) 0.0081\n",
      "18m 12s (- 18m 54s) (36800 49%) 0.0099\n",
      "18m 14s (- 18m 52s) (36850 49%) 0.0063\n",
      "18m 15s (- 18m 51s) (36900 49%) 0.0128\n",
      "18m 17s (- 18m 49s) (36950 49%) 0.0075\n",
      "18m 18s (- 18m 48s) (37000 49%) 0.0117\n",
      "18m 19s (- 18m 46s) (37050 49%) 0.0224\n",
      "18m 21s (- 18m 45s) (37100 49%) 0.0068\n",
      "18m 22s (- 18m 43s) (37150 49%) 0.0088\n",
      "18m 24s (- 18m 42s) (37200 49%) 0.0071\n",
      "18m 25s (- 18m 40s) (37250 49%) 0.0080\n",
      "18m 27s (- 18m 39s) (37300 49%) 0.0069\n",
      "18m 28s (- 18m 37s) (37350 49%) 0.0066\n",
      "18m 30s (- 18m 36s) (37400 49%) 0.0164\n",
      "18m 31s (- 18m 34s) (37450 49%) 0.0045\n",
      "18m 33s (- 18m 33s) (37500 50%) 0.0045\n",
      "18m 34s (- 18m 31s) (37550 50%) 0.0063\n",
      "18m 36s (- 18m 30s) (37600 50%) 0.0116\n",
      "18m 37s (- 18m 28s) (37650 50%) 0.0112\n",
      "18m 39s (- 18m 27s) (37700 50%) 0.0109\n",
      "18m 40s (- 18m 25s) (37750 50%) 0.0058\n",
      "18m 42s (- 18m 24s) (37800 50%) 0.0073\n",
      "18m 43s (- 18m 22s) (37850 50%) 0.0052\n",
      "18m 45s (- 18m 21s) (37900 50%) 0.0046\n",
      "18m 46s (- 18m 19s) (37950 50%) 0.0097\n",
      "18m 48s (- 18m 18s) (38000 50%) 0.0086\n",
      "18m 49s (- 18m 17s) (38050 50%) 0.0103\n",
      "18m 51s (- 18m 15s) (38100 50%) 0.0051\n",
      "18m 52s (- 18m 14s) (38150 50%) 0.0075\n",
      "18m 54s (- 18m 12s) (38200 50%) 0.0049\n",
      "18m 55s (- 18m 11s) (38250 51%) 0.0054\n",
      "18m 57s (- 18m 9s) (38300 51%) 0.0061\n",
      "18m 58s (- 18m 8s) (38350 51%) 0.0113\n",
      "19m 0s (- 18m 6s) (38400 51%) 0.0072\n",
      "19m 1s (- 18m 5s) (38450 51%) 0.0055\n",
      "19m 3s (- 18m 4s) (38500 51%) 0.0100\n",
      "19m 5s (- 18m 2s) (38550 51%) 0.0141\n",
      "19m 6s (- 18m 1s) (38600 51%) 0.0117\n",
      "19m 8s (- 17m 59s) (38650 51%) 0.0045\n",
      "19m 9s (- 17m 58s) (38700 51%) 0.0079\n",
      "19m 11s (- 17m 56s) (38750 51%) 0.0065\n",
      "19m 12s (- 17m 55s) (38800 51%) 0.0049\n",
      "19m 13s (- 17m 53s) (38850 51%) 0.0100\n",
      "19m 15s (- 17m 52s) (38900 51%) 0.0041\n",
      "19m 16s (- 17m 50s) (38950 51%) 0.0110\n",
      "19m 18s (- 17m 49s) (39000 52%) 0.0049\n",
      "19m 19s (- 17m 47s) (39050 52%) 0.0043\n",
      "19m 21s (- 17m 46s) (39100 52%) 0.0035\n",
      "19m 22s (- 17m 44s) (39150 52%) 0.0102\n",
      "19m 24s (- 17m 43s) (39200 52%) 0.0072\n",
      "19m 25s (- 17m 42s) (39250 52%) 0.0042\n",
      "19m 27s (- 17m 40s) (39300 52%) 0.0045\n",
      "19m 28s (- 17m 39s) (39350 52%) 0.0077\n",
      "19m 30s (- 17m 37s) (39400 52%) 0.0038\n",
      "19m 31s (- 17m 36s) (39450 52%) 0.0078\n",
      "19m 33s (- 17m 34s) (39500 52%) 0.0054\n",
      "19m 34s (- 17m 33s) (39550 52%) 0.0131\n",
      "19m 36s (- 17m 31s) (39600 52%) 0.0092\n",
      "19m 37s (- 17m 30s) (39650 52%) 0.0046\n",
      "19m 39s (- 17m 28s) (39700 52%) 0.0060\n",
      "19m 40s (- 17m 27s) (39750 53%) 0.0058\n",
      "19m 42s (- 17m 25s) (39800 53%) 0.0112\n",
      "19m 43s (- 17m 23s) (39850 53%) 0.0094\n",
      "19m 45s (- 17m 22s) (39900 53%) 0.0051\n",
      "19m 46s (- 17m 21s) (39950 53%) 0.0090\n",
      "19m 48s (- 17m 19s) (40000 53%) 0.0089\n",
      "19m 49s (- 17m 18s) (40050 53%) 0.0056\n",
      "19m 51s (- 17m 16s) (40100 53%) 0.0084\n",
      "19m 52s (- 17m 15s) (40150 53%) 0.0069\n",
      "19m 54s (- 17m 13s) (40200 53%) 0.0197\n",
      "19m 55s (- 17m 12s) (40250 53%) 0.0039\n",
      "19m 57s (- 17m 10s) (40300 53%) 0.0071\n",
      "19m 58s (- 17m 9s) (40350 53%) 0.0123\n",
      "20m 0s (- 17m 8s) (40400 53%) 0.0049\n",
      "20m 1s (- 17m 6s) (40450 53%) 0.0089\n",
      "20m 3s (- 17m 5s) (40500 54%) 0.0072\n",
      "20m 4s (- 17m 3s) (40550 54%) 0.0031\n",
      "20m 6s (- 17m 2s) (40600 54%) 0.0109\n",
      "20m 8s (- 17m 0s) (40650 54%) 0.0040\n",
      "20m 9s (- 16m 59s) (40700 54%) 0.0059\n",
      "20m 11s (- 16m 57s) (40750 54%) 0.0030\n",
      "20m 12s (- 16m 56s) (40800 54%) 0.0032\n",
      "20m 14s (- 16m 55s) (40850 54%) 0.0066\n",
      "20m 15s (- 16m 53s) (40900 54%) 0.0050\n",
      "20m 17s (- 16m 52s) (40950 54%) 0.0038\n",
      "20m 18s (- 16m 50s) (41000 54%) 0.0058\n",
      "20m 20s (- 16m 49s) (41050 54%) 0.0036\n",
      "20m 21s (- 16m 47s) (41100 54%) 0.0034\n",
      "20m 23s (- 16m 46s) (41150 54%) 0.0080\n",
      "20m 24s (- 16m 44s) (41200 54%) 0.0072\n",
      "20m 26s (- 16m 43s) (41250 55%) 0.0040\n",
      "20m 27s (- 16m 41s) (41300 55%) 0.0029\n",
      "20m 29s (- 16m 40s) (41350 55%) 0.0056\n",
      "20m 30s (- 16m 38s) (41400 55%) 0.0071\n",
      "20m 32s (- 16m 37s) (41450 55%) 0.0037\n",
      "20m 33s (- 16m 35s) (41500 55%) 0.0042\n",
      "20m 35s (- 16m 34s) (41550 55%) 0.0058\n",
      "20m 36s (- 16m 32s) (41600 55%) 0.0058\n",
      "20m 38s (- 16m 31s) (41650 55%) 0.0049\n",
      "20m 39s (- 16m 30s) (41700 55%) 0.0022\n",
      "20m 41s (- 16m 28s) (41750 55%) 0.0098\n",
      "20m 42s (- 16m 27s) (41800 55%) 0.0105\n",
      "20m 44s (- 16m 25s) (41850 55%) 0.0083\n",
      "20m 45s (- 16m 24s) (41900 55%) 0.0063\n",
      "20m 47s (- 16m 22s) (41950 55%) 0.0055\n",
      "20m 48s (- 16m 21s) (42000 56%) 0.0048\n",
      "20m 50s (- 16m 19s) (42050 56%) 0.0077\n",
      "20m 51s (- 16m 18s) (42100 56%) 0.0063\n",
      "20m 53s (- 16m 16s) (42150 56%) 0.0074\n",
      "20m 54s (- 16m 15s) (42200 56%) 0.0054\n",
      "20m 56s (- 16m 13s) (42250 56%) 0.0047\n",
      "20m 57s (- 16m 12s) (42300 56%) 0.0065\n",
      "20m 59s (- 16m 10s) (42350 56%) 0.0067\n",
      "21m 0s (- 16m 9s) (42400 56%) 0.0167\n",
      "21m 2s (- 16m 7s) (42450 56%) 0.0042\n",
      "21m 3s (- 16m 6s) (42500 56%) 0.0082\n",
      "21m 5s (- 16m 4s) (42550 56%) 0.0080\n",
      "21m 6s (- 16m 3s) (42600 56%) 0.0111\n",
      "21m 8s (- 16m 1s) (42650 56%) 0.0067\n",
      "21m 9s (- 16m 0s) (42700 56%) 0.0071\n",
      "21m 10s (- 15m 58s) (42750 56%) 0.0027\n",
      "21m 12s (- 15m 57s) (42800 57%) 0.0046\n",
      "21m 13s (- 15m 55s) (42850 57%) 0.0073\n",
      "21m 15s (- 15m 54s) (42900 57%) 0.0024\n",
      "21m 17s (- 15m 52s) (42950 57%) 0.0033\n",
      "21m 18s (- 15m 51s) (43000 57%) 0.0060\n",
      "21m 20s (- 15m 50s) (43050 57%) 0.0026\n",
      "21m 21s (- 15m 48s) (43100 57%) 0.0056\n",
      "21m 23s (- 15m 47s) (43150 57%) 0.0049\n",
      "21m 24s (- 15m 45s) (43200 57%) 0.0054\n",
      "21m 25s (- 15m 44s) (43250 57%) 0.0067\n",
      "21m 27s (- 15m 42s) (43300 57%) 0.0086\n",
      "21m 28s (- 15m 40s) (43350 57%) 0.0029\n",
      "21m 30s (- 15m 39s) (43400 57%) 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21m 31s (- 15m 37s) (43450 57%) 0.0030\n",
      "21m 33s (- 15m 36s) (43500 57%) 0.0074\n",
      "21m 34s (- 15m 34s) (43550 58%) 0.0048\n",
      "21m 36s (- 15m 33s) (43600 58%) 0.0053\n",
      "21m 37s (- 15m 32s) (43650 58%) 0.0046\n",
      "21m 39s (- 15m 30s) (43700 58%) 0.0093\n",
      "21m 40s (- 15m 28s) (43750 58%) 0.0083\n",
      "21m 42s (- 15m 27s) (43800 58%) 0.0059\n",
      "21m 43s (- 15m 26s) (43850 58%) 0.0125\n",
      "21m 45s (- 15m 24s) (43900 58%) 0.0031\n",
      "21m 46s (- 15m 23s) (43950 58%) 0.0073\n",
      "21m 48s (- 15m 21s) (44000 58%) 0.0041\n",
      "21m 49s (- 15m 20s) (44050 58%) 0.0138\n",
      "21m 51s (- 15m 18s) (44100 58%) 0.0049\n",
      "21m 52s (- 15m 17s) (44150 58%) 0.0042\n",
      "21m 54s (- 15m 15s) (44200 58%) 0.0088\n",
      "21m 55s (- 15m 14s) (44250 59%) 0.0047\n",
      "21m 57s (- 15m 12s) (44300 59%) 0.0132\n",
      "21m 58s (- 15m 11s) (44350 59%) 0.0066\n",
      "22m 0s (- 15m 10s) (44400 59%) 0.0041\n",
      "22m 2s (- 15m 8s) (44450 59%) 0.0056\n",
      "22m 3s (- 15m 7s) (44500 59%) 0.0053\n",
      "22m 5s (- 15m 5s) (44550 59%) 0.0076\n",
      "22m 6s (- 15m 4s) (44600 59%) 0.0057\n",
      "22m 8s (- 15m 2s) (44650 59%) 0.0043\n",
      "22m 9s (- 15m 1s) (44700 59%) 0.0033\n",
      "22m 11s (- 14m 59s) (44750 59%) 0.0069\n",
      "22m 12s (- 14m 58s) (44800 59%) 0.0054\n",
      "22m 14s (- 14m 57s) (44850 59%) 0.0080\n",
      "22m 16s (- 14m 55s) (44900 59%) 0.0025\n",
      "22m 17s (- 14m 54s) (44950 59%) 0.0046\n",
      "22m 19s (- 14m 52s) (45000 60%) 0.0031\n",
      "22m 20s (- 14m 51s) (45050 60%) 0.0024\n",
      "22m 21s (- 14m 49s) (45100 60%) 0.0046\n",
      "22m 23s (- 14m 48s) (45150 60%) 0.0059\n",
      "22m 25s (- 14m 46s) (45200 60%) 0.0126\n",
      "22m 26s (- 14m 45s) (45250 60%) 0.0029\n",
      "22m 28s (- 14m 43s) (45300 60%) 0.0046\n",
      "22m 29s (- 14m 42s) (45350 60%) 0.0054\n",
      "22m 31s (- 14m 40s) (45400 60%) 0.0042\n",
      "22m 32s (- 14m 39s) (45450 60%) 0.0034\n",
      "22m 34s (- 14m 38s) (45500 60%) 0.0028\n",
      "22m 35s (- 14m 36s) (45550 60%) 0.0026\n",
      "22m 37s (- 14m 35s) (45600 60%) 0.0029\n",
      "22m 38s (- 14m 33s) (45650 60%) 0.0027\n",
      "22m 40s (- 14m 32s) (45700 60%) 0.0108\n",
      "22m 41s (- 14m 30s) (45750 61%) 0.0093\n",
      "22m 43s (- 14m 29s) (45800 61%) 0.0029\n",
      "22m 44s (- 14m 27s) (45850 61%) 0.0027\n",
      "22m 46s (- 14m 26s) (45900 61%) 0.0047\n",
      "22m 47s (- 14m 24s) (45950 61%) 0.0062\n",
      "22m 49s (- 14m 23s) (46000 61%) 0.0037\n",
      "22m 50s (- 14m 21s) (46050 61%) 0.0029\n",
      "22m 52s (- 14m 20s) (46100 61%) 0.0063\n",
      "22m 53s (- 14m 18s) (46150 61%) 0.0052\n",
      "22m 55s (- 14m 17s) (46200 61%) 0.0037\n",
      "22m 56s (- 14m 15s) (46250 61%) 0.0030\n",
      "22m 58s (- 14m 14s) (46300 61%) 0.0026\n",
      "22m 59s (- 14m 12s) (46350 61%) 0.0048\n",
      "23m 1s (- 14m 11s) (46400 61%) 0.0032\n",
      "23m 2s (- 14m 9s) (46450 61%) 0.0064\n",
      "23m 4s (- 14m 8s) (46500 62%) 0.0081\n",
      "23m 5s (- 14m 7s) (46550 62%) 0.0029\n",
      "23m 7s (- 14m 5s) (46600 62%) 0.0034\n",
      "23m 8s (- 14m 4s) (46650 62%) 0.0045\n",
      "23m 10s (- 14m 2s) (46700 62%) 0.0031\n",
      "23m 11s (- 14m 1s) (46750 62%) 0.0035\n",
      "23m 13s (- 13m 59s) (46800 62%) 0.0121\n",
      "23m 14s (- 13m 58s) (46850 62%) 0.0064\n",
      "23m 16s (- 13m 56s) (46900 62%) 0.0112\n",
      "23m 17s (- 13m 55s) (46950 62%) 0.0070\n",
      "23m 19s (- 13m 53s) (47000 62%) 0.0031\n",
      "23m 20s (- 13m 52s) (47050 62%) 0.0099\n",
      "23m 22s (- 13m 50s) (47100 62%) 0.0035\n",
      "23m 23s (- 13m 49s) (47150 62%) 0.0028\n",
      "23m 25s (- 13m 47s) (47200 62%) 0.0052\n",
      "23m 26s (- 13m 46s) (47250 63%) 0.0082\n",
      "23m 27s (- 13m 44s) (47300 63%) 0.0037\n",
      "23m 29s (- 13m 42s) (47350 63%) 0.0052\n",
      "23m 30s (- 13m 41s) (47400 63%) 0.0049\n",
      "23m 32s (- 13m 39s) (47450 63%) 0.0031\n",
      "23m 33s (- 13m 38s) (47500 63%) 0.0047\n",
      "23m 35s (- 13m 36s) (47550 63%) 0.0036\n",
      "23m 36s (- 13m 35s) (47600 63%) 0.0031\n",
      "23m 38s (- 13m 34s) (47650 63%) 0.0048\n",
      "23m 39s (- 13m 32s) (47700 63%) 0.0037\n",
      "23m 41s (- 13m 31s) (47750 63%) 0.0022\n",
      "23m 42s (- 13m 29s) (47800 63%) 0.0170\n",
      "23m 44s (- 13m 28s) (47850 63%) 0.0031\n",
      "23m 45s (- 13m 26s) (47900 63%) 0.0036\n",
      "23m 47s (- 13m 25s) (47950 63%) 0.0117\n",
      "23m 48s (- 13m 23s) (48000 64%) 0.0321\n",
      "23m 50s (- 13m 22s) (48050 64%) 0.0079\n",
      "23m 51s (- 13m 20s) (48100 64%) 0.0129\n",
      "23m 53s (- 13m 19s) (48150 64%) 0.0050\n",
      "23m 54s (- 13m 17s) (48200 64%) 0.0047\n",
      "23m 56s (- 13m 16s) (48250 64%) 0.0056\n",
      "23m 57s (- 13m 14s) (48300 64%) 0.0033\n",
      "23m 59s (- 13m 13s) (48350 64%) 0.0122\n",
      "24m 0s (- 13m 11s) (48400 64%) 0.0039\n",
      "24m 1s (- 13m 10s) (48450 64%) 0.0020\n",
      "24m 3s (- 13m 8s) (48500 64%) 0.0152\n",
      "24m 4s (- 13m 7s) (48550 64%) 0.0121\n",
      "24m 6s (- 13m 5s) (48600 64%) 0.0030\n",
      "24m 7s (- 13m 4s) (48650 64%) 0.0028\n",
      "24m 9s (- 13m 2s) (48700 64%) 0.0130\n",
      "24m 10s (- 13m 1s) (48750 65%) 0.0115\n",
      "24m 12s (- 12m 59s) (48800 65%) 0.0088\n",
      "24m 13s (- 12m 58s) (48850 65%) 0.0053\n",
      "24m 15s (- 12m 56s) (48900 65%) 0.0059\n",
      "24m 16s (- 12m 55s) (48950 65%) 0.0129\n",
      "24m 18s (- 12m 53s) (49000 65%) 0.0034\n",
      "24m 19s (- 12m 52s) (49050 65%) 0.0041\n",
      "24m 20s (- 12m 50s) (49100 65%) 0.0020\n",
      "24m 22s (- 12m 49s) (49150 65%) 0.0045\n",
      "24m 23s (- 12m 47s) (49200 65%) 0.0058\n",
      "24m 25s (- 12m 46s) (49250 65%) 0.0089\n",
      "24m 27s (- 12m 44s) (49300 65%) 0.0054\n",
      "24m 28s (- 12m 43s) (49350 65%) 0.0033\n",
      "24m 30s (- 12m 41s) (49400 65%) 0.0025\n",
      "24m 31s (- 12m 40s) (49450 65%) 0.0063\n",
      "24m 33s (- 12m 38s) (49500 66%) 0.0043\n",
      "24m 34s (- 12m 37s) (49550 66%) 0.0053\n",
      "24m 36s (- 12m 35s) (49600 66%) 0.0066\n",
      "24m 37s (- 12m 34s) (49650 66%) 0.0035\n",
      "24m 39s (- 12m 32s) (49700 66%) 0.0044\n",
      "24m 40s (- 12m 31s) (49750 66%) 0.0115\n",
      "24m 42s (- 12m 30s) (49800 66%) 0.0071\n",
      "24m 43s (- 12m 28s) (49850 66%) 0.0106\n",
      "24m 45s (- 12m 27s) (49900 66%) 0.0073\n",
      "24m 46s (- 12m 25s) (49950 66%) 0.0047\n",
      "24m 48s (- 12m 24s) (50000 66%) 0.0079\n",
      "24m 49s (- 12m 22s) (50050 66%) 0.0027\n",
      "24m 51s (- 12m 21s) (50100 66%) 0.0053\n",
      "24m 52s (- 12m 19s) (50150 66%) 0.0049\n",
      "24m 54s (- 12m 18s) (50200 66%) 0.0090\n",
      "24m 56s (- 12m 16s) (50250 67%) 0.0063\n",
      "24m 57s (- 12m 15s) (50300 67%) 0.0041\n",
      "24m 59s (- 12m 13s) (50350 67%) 0.0031\n",
      "25m 0s (- 12m 12s) (50400 67%) 0.0056\n",
      "25m 2s (- 12m 10s) (50450 67%) 0.0027\n",
      "25m 3s (- 12m 9s) (50500 67%) 0.0042\n",
      "25m 5s (- 12m 7s) (50550 67%) 0.0042\n",
      "25m 6s (- 12m 6s) (50600 67%) 0.0056\n",
      "25m 8s (- 12m 4s) (50650 67%) 0.0092\n",
      "25m 9s (- 12m 3s) (50700 67%) 0.0027\n",
      "25m 11s (- 12m 2s) (50750 67%) 0.0206\n",
      "25m 12s (- 12m 0s) (50800 67%) 0.0065\n",
      "25m 14s (- 11m 59s) (50850 67%) 0.0042\n",
      "25m 15s (- 11m 57s) (50900 67%) 0.0046\n",
      "25m 17s (- 11m 56s) (50950 67%) 0.0049\n",
      "25m 18s (- 11m 54s) (51000 68%) 0.0063\n",
      "25m 20s (- 11m 53s) (51050 68%) 0.0058\n",
      "25m 21s (- 11m 51s) (51100 68%) 0.0039\n",
      "25m 23s (- 11m 50s) (51150 68%) 0.0028\n",
      "25m 24s (- 11m 48s) (51200 68%) 0.0052\n",
      "25m 26s (- 11m 47s) (51250 68%) 0.0047\n",
      "25m 27s (- 11m 45s) (51300 68%) 0.0030\n",
      "25m 29s (- 11m 44s) (51350 68%) 0.0018\n",
      "25m 30s (- 11m 42s) (51400 68%) 0.0039\n",
      "25m 32s (- 11m 41s) (51450 68%) 0.0055\n",
      "25m 33s (- 11m 39s) (51500 68%) 0.0077\n",
      "25m 35s (- 11m 38s) (51550 68%) 0.0096\n",
      "25m 36s (- 11m 36s) (51600 68%) 0.0037\n",
      "25m 38s (- 11m 35s) (51650 68%) 0.0059\n",
      "25m 39s (- 11m 33s) (51700 68%) 0.0032\n",
      "25m 41s (- 11m 32s) (51750 69%) 0.0044\n",
      "25m 43s (- 11m 31s) (51800 69%) 0.0032\n",
      "25m 44s (- 11m 29s) (51850 69%) 0.0023\n",
      "25m 46s (- 11m 28s) (51900 69%) 0.0080\n",
      "25m 47s (- 11m 26s) (51950 69%) 0.0038\n",
      "25m 48s (- 11m 25s) (52000 69%) 0.0029\n",
      "25m 50s (- 11m 23s) (52050 69%) 0.0048\n",
      "25m 51s (- 11m 22s) (52100 69%) 0.0023\n",
      "25m 53s (- 11m 20s) (52150 69%) 0.0051\n",
      "25m 54s (- 11m 19s) (52200 69%) 0.0045\n",
      "25m 56s (- 11m 17s) (52250 69%) 0.0104\n",
      "25m 57s (- 11m 16s) (52300 69%) 0.0041\n",
      "25m 59s (- 11m 14s) (52350 69%) 0.0027\n",
      "26m 0s (- 11m 13s) (52400 69%) 0.0027\n",
      "26m 1s (- 11m 11s) (52450 69%) 0.0040\n",
      "26m 3s (- 11m 10s) (52500 70%) 0.0076\n",
      "26m 4s (- 11m 8s) (52550 70%) 0.0056\n",
      "26m 6s (- 11m 7s) (52600 70%) 0.0061\n",
      "26m 7s (- 11m 5s) (52650 70%) 0.0053\n",
      "26m 9s (- 11m 4s) (52700 70%) 0.0170\n",
      "26m 10s (- 11m 2s) (52750 70%) 0.0086\n",
      "26m 12s (- 11m 1s) (52800 70%) 0.0033\n",
      "26m 13s (- 10m 59s) (52850 70%) 0.0071\n",
      "26m 15s (- 10m 58s) (52900 70%) 0.0091\n",
      "26m 17s (- 10m 56s) (52950 70%) 0.0030\n",
      "26m 18s (- 10m 55s) (53000 70%) 0.0041\n",
      "26m 20s (- 10m 53s) (53050 70%) 0.0031\n",
      "26m 21s (- 10m 52s) (53100 70%) 0.0091\n",
      "26m 23s (- 10m 50s) (53150 70%) 0.0036\n",
      "26m 24s (- 10m 49s) (53200 70%) 0.0087\n",
      "26m 26s (- 10m 47s) (53250 71%) 0.0062\n",
      "26m 27s (- 10m 46s) (53300 71%) 0.0031\n",
      "26m 28s (- 10m 44s) (53350 71%) 0.0039\n",
      "26m 30s (- 10m 43s) (53400 71%) 0.0028\n",
      "26m 31s (- 10m 41s) (53450 71%) 0.0091\n",
      "26m 33s (- 10m 40s) (53500 71%) 0.0041\n",
      "26m 34s (- 10m 38s) (53550 71%) 0.0042\n",
      "26m 36s (- 10m 37s) (53600 71%) 0.0042\n",
      "26m 37s (- 10m 35s) (53650 71%) 0.0066\n",
      "26m 39s (- 10m 34s) (53700 71%) 0.0054\n",
      "26m 40s (- 10m 32s) (53750 71%) 0.0043\n",
      "26m 42s (- 10m 31s) (53800 71%) 0.0067\n",
      "26m 43s (- 10m 29s) (53850 71%) 0.0023\n",
      "26m 45s (- 10m 28s) (53900 71%) 0.0036\n",
      "26m 46s (- 10m 27s) (53950 71%) 0.0086\n",
      "26m 48s (- 10m 25s) (54000 72%) 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26m 50s (- 10m 24s) (54050 72%) 0.0079\n",
      "26m 51s (- 10m 22s) (54100 72%) 0.0062\n",
      "26m 52s (- 10m 21s) (54150 72%) 0.0034\n",
      "26m 54s (- 10m 19s) (54200 72%) 0.0066\n",
      "26m 56s (- 10m 18s) (54250 72%) 0.0026\n",
      "26m 57s (- 10m 16s) (54300 72%) 0.0025\n",
      "26m 59s (- 10m 15s) (54350 72%) 0.0038\n",
      "27m 0s (- 10m 13s) (54400 72%) 0.0038\n",
      "27m 2s (- 10m 12s) (54450 72%) 0.0058\n",
      "27m 3s (- 10m 10s) (54500 72%) 0.0048\n",
      "27m 5s (- 10m 9s) (54550 72%) 0.0023\n",
      "27m 6s (- 10m 7s) (54600 72%) 0.0099\n",
      "27m 8s (- 10m 6s) (54650 72%) 0.0042\n",
      "27m 9s (- 10m 4s) (54700 72%) 0.0024\n",
      "27m 11s (- 10m 3s) (54750 73%) 0.0045\n",
      "27m 12s (- 10m 1s) (54800 73%) 0.0047\n",
      "27m 13s (- 10m 0s) (54850 73%) 0.0053\n",
      "27m 15s (- 9m 58s) (54900 73%) 0.0022\n",
      "27m 16s (- 9m 57s) (54950 73%) 0.0042\n",
      "27m 18s (- 9m 55s) (55000 73%) 0.0032\n",
      "27m 20s (- 9m 54s) (55050 73%) 0.0023\n",
      "27m 21s (- 9m 52s) (55100 73%) 0.0026\n",
      "27m 23s (- 9m 51s) (55150 73%) 0.0014\n",
      "27m 24s (- 9m 49s) (55200 73%) 0.0018\n",
      "27m 26s (- 9m 48s) (55250 73%) 0.0030\n",
      "27m 27s (- 9m 46s) (55300 73%) 0.0020\n",
      "27m 29s (- 9m 45s) (55350 73%) 0.0020\n",
      "27m 30s (- 9m 44s) (55400 73%) 0.0045\n",
      "27m 32s (- 9m 42s) (55450 73%) 0.0058\n",
      "27m 33s (- 9m 41s) (55500 74%) 0.0032\n",
      "27m 35s (- 9m 39s) (55550 74%) 0.0117\n",
      "27m 36s (- 9m 38s) (55600 74%) 0.0024\n",
      "27m 38s (- 9m 36s) (55650 74%) 0.0029\n",
      "27m 39s (- 9m 35s) (55700 74%) 0.0028\n",
      "27m 41s (- 9m 33s) (55750 74%) 0.0041\n",
      "27m 42s (- 9m 32s) (55800 74%) 0.0069\n",
      "27m 44s (- 9m 30s) (55850 74%) 0.0034\n",
      "27m 45s (- 9m 29s) (55900 74%) 0.0025\n",
      "27m 47s (- 9m 27s) (55950 74%) 0.0020\n",
      "27m 48s (- 9m 26s) (56000 74%) 0.0029\n",
      "27m 50s (- 9m 24s) (56050 74%) 0.0020\n",
      "27m 51s (- 9m 23s) (56100 74%) 0.0033\n",
      "27m 53s (- 9m 21s) (56150 74%) 0.0015\n",
      "27m 54s (- 9m 20s) (56200 74%) 0.0020\n",
      "27m 56s (- 9m 18s) (56250 75%) 0.0038\n",
      "27m 57s (- 9m 17s) (56300 75%) 0.0025\n",
      "27m 59s (- 9m 15s) (56350 75%) 0.0028\n",
      "28m 0s (- 9m 14s) (56400 75%) 0.0032\n",
      "28m 1s (- 9m 12s) (56450 75%) 0.0036\n",
      "28m 3s (- 9m 11s) (56500 75%) 0.0053\n",
      "28m 4s (- 9m 9s) (56550 75%) 0.0041\n",
      "28m 6s (- 9m 8s) (56600 75%) 0.0027\n",
      "28m 7s (- 9m 6s) (56650 75%) 0.0034\n",
      "28m 9s (- 9m 5s) (56700 75%) 0.0031\n",
      "28m 10s (- 9m 3s) (56750 75%) 0.0043\n",
      "28m 12s (- 9m 2s) (56800 75%) 0.0027\n",
      "28m 13s (- 9m 0s) (56850 75%) 0.0034\n",
      "28m 15s (- 8m 59s) (56900 75%) 0.0063\n",
      "28m 16s (- 8m 57s) (56950 75%) 0.0080\n",
      "28m 18s (- 8m 56s) (57000 76%) 0.0024\n",
      "28m 19s (- 8m 54s) (57050 76%) 0.0037\n",
      "28m 21s (- 8m 53s) (57100 76%) 0.0024\n",
      "28m 22s (- 8m 51s) (57150 76%) 0.0031\n",
      "28m 23s (- 8m 50s) (57200 76%) 0.0021\n",
      "28m 25s (- 8m 48s) (57250 76%) 0.0031\n",
      "28m 27s (- 8m 47s) (57300 76%) 0.0051\n",
      "28m 28s (- 8m 45s) (57350 76%) 0.0025\n",
      "28m 29s (- 8m 44s) (57400 76%) 0.0034\n",
      "28m 31s (- 8m 42s) (57450 76%) 0.0052\n",
      "28m 32s (- 8m 41s) (57500 76%) 0.0016\n",
      "28m 34s (- 8m 39s) (57550 76%) 0.0180\n",
      "28m 36s (- 8m 38s) (57600 76%) 0.0033\n",
      "28m 37s (- 8m 36s) (57650 76%) 0.0068\n",
      "28m 38s (- 8m 35s) (57700 76%) 0.0052\n",
      "28m 40s (- 8m 33s) (57750 77%) 0.0021\n",
      "28m 41s (- 8m 32s) (57800 77%) 0.0051\n",
      "28m 43s (- 8m 30s) (57850 77%) 0.0039\n",
      "28m 44s (- 8m 29s) (57900 77%) 0.0023\n",
      "28m 46s (- 8m 27s) (57950 77%) 0.0049\n",
      "28m 48s (- 8m 26s) (58000 77%) 0.0056\n",
      "28m 49s (- 8m 24s) (58050 77%) 0.0012\n",
      "28m 51s (- 8m 23s) (58100 77%) 0.0029\n",
      "28m 52s (- 8m 22s) (58150 77%) 0.0021\n",
      "28m 54s (- 8m 20s) (58200 77%) 0.0045\n",
      "28m 55s (- 8m 19s) (58250 77%) 0.0034\n",
      "28m 57s (- 8m 17s) (58300 77%) 0.0019\n",
      "28m 58s (- 8m 16s) (58350 77%) 0.0030\n",
      "29m 0s (- 8m 14s) (58400 77%) 0.0018\n",
      "29m 1s (- 8m 13s) (58450 77%) 0.0036\n",
      "29m 3s (- 8m 11s) (58500 78%) 0.0037\n",
      "29m 4s (- 8m 10s) (58550 78%) 0.0040\n",
      "29m 6s (- 8m 8s) (58600 78%) 0.0028\n",
      "29m 7s (- 8m 7s) (58650 78%) 0.0036\n",
      "29m 9s (- 8m 5s) (58700 78%) 0.0015\n",
      "29m 10s (- 8m 4s) (58750 78%) 0.0015\n",
      "29m 12s (- 8m 2s) (58800 78%) 0.0023\n",
      "29m 13s (- 8m 1s) (58850 78%) 0.0028\n",
      "29m 14s (- 7m 59s) (58900 78%) 0.0024\n",
      "29m 16s (- 7m 58s) (58950 78%) 0.0035\n",
      "29m 17s (- 7m 56s) (59000 78%) 0.0030\n",
      "29m 19s (- 7m 55s) (59050 78%) 0.0030\n",
      "29m 20s (- 7m 53s) (59100 78%) 0.0025\n",
      "29m 22s (- 7m 52s) (59150 78%) 0.0024\n",
      "29m 23s (- 7m 50s) (59200 78%) 0.0030\n",
      "29m 25s (- 7m 49s) (59250 79%) 0.0031\n",
      "29m 26s (- 7m 47s) (59300 79%) 0.0023\n",
      "29m 28s (- 7m 46s) (59350 79%) 0.0035\n",
      "29m 29s (- 7m 44s) (59400 79%) 0.0047\n",
      "29m 31s (- 7m 43s) (59450 79%) 0.0038\n",
      "29m 32s (- 7m 41s) (59500 79%) 0.0023\n",
      "29m 34s (- 7m 40s) (59550 79%) 0.0032\n",
      "29m 35s (- 7m 38s) (59600 79%) 0.0038\n",
      "29m 36s (- 7m 37s) (59650 79%) 0.0055\n",
      "29m 38s (- 7m 35s) (59700 79%) 0.0069\n",
      "29m 40s (- 7m 34s) (59750 79%) 0.0023\n",
      "29m 41s (- 7m 32s) (59800 79%) 0.0042\n",
      "29m 42s (- 7m 31s) (59850 79%) 0.0023\n",
      "29m 44s (- 7m 29s) (59900 79%) 0.0030\n",
      "29m 45s (- 7m 28s) (59950 79%) 0.0025\n",
      "29m 47s (- 7m 26s) (60000 80%) 0.0031\n",
      "29m 49s (- 7m 25s) (60050 80%) 0.0030\n",
      "29m 50s (- 7m 23s) (60100 80%) 0.0025\n",
      "29m 52s (- 7m 22s) (60150 80%) 0.0043\n",
      "29m 53s (- 7m 20s) (60200 80%) 0.0016\n",
      "29m 55s (- 7m 19s) (60250 80%) 0.0023\n",
      "29m 56s (- 7m 18s) (60300 80%) 0.0016\n",
      "29m 58s (- 7m 16s) (60350 80%) 0.0023\n",
      "29m 59s (- 7m 15s) (60400 80%) 0.0051\n",
      "30m 1s (- 7m 13s) (60450 80%) 0.0030\n",
      "30m 2s (- 7m 12s) (60500 80%) 0.0026\n",
      "30m 4s (- 7m 10s) (60550 80%) 0.0038\n",
      "30m 6s (- 7m 9s) (60600 80%) 0.0018\n",
      "30m 7s (- 7m 7s) (60650 80%) 0.0019\n",
      "30m 9s (- 7m 6s) (60700 80%) 0.0019\n",
      "30m 10s (- 7m 4s) (60750 81%) 0.0027\n",
      "30m 11s (- 7m 3s) (60800 81%) 0.0023\n",
      "30m 13s (- 7m 1s) (60850 81%) 0.0028\n",
      "30m 14s (- 7m 0s) (60900 81%) 0.0045\n",
      "30m 16s (- 6m 58s) (60950 81%) 0.0081\n",
      "30m 17s (- 6m 57s) (61000 81%) 0.0024\n",
      "30m 19s (- 6m 55s) (61050 81%) 0.0021\n",
      "30m 20s (- 6m 54s) (61100 81%) 0.0025\n",
      "30m 22s (- 6m 52s) (61150 81%) 0.0018\n",
      "30m 23s (- 6m 51s) (61200 81%) 0.0038\n",
      "30m 25s (- 6m 49s) (61250 81%) 0.0020\n",
      "30m 26s (- 6m 48s) (61300 81%) 0.0017\n",
      "30m 28s (- 6m 46s) (61350 81%) 0.0015\n",
      "30m 29s (- 6m 45s) (61400 81%) 0.0017\n",
      "30m 30s (- 6m 43s) (61450 81%) 0.0033\n",
      "30m 32s (- 6m 42s) (61500 82%) 0.0020\n",
      "30m 33s (- 6m 40s) (61550 82%) 0.0034\n",
      "30m 35s (- 6m 39s) (61600 82%) 0.0031\n",
      "30m 36s (- 6m 37s) (61650 82%) 0.0036\n",
      "30m 38s (- 6m 36s) (61700 82%) 0.0020\n",
      "30m 39s (- 6m 34s) (61750 82%) 0.0057\n",
      "30m 40s (- 6m 33s) (61800 82%) 0.0019\n",
      "30m 42s (- 6m 31s) (61850 82%) 0.0020\n",
      "30m 43s (- 6m 30s) (61900 82%) 0.0027\n",
      "30m 45s (- 6m 28s) (61950 82%) 0.0014\n",
      "30m 46s (- 6m 27s) (62000 82%) 0.0037\n",
      "30m 47s (- 6m 25s) (62050 82%) 0.0023\n",
      "30m 49s (- 6m 24s) (62100 82%) 0.0022\n",
      "30m 50s (- 6m 22s) (62150 82%) 0.0022\n",
      "30m 52s (- 6m 21s) (62200 82%) 0.0015\n",
      "30m 54s (- 6m 19s) (62250 83%) 0.0035\n",
      "30m 55s (- 6m 18s) (62300 83%) 0.0035\n",
      "30m 57s (- 6m 16s) (62350 83%) 0.0024\n",
      "30m 58s (- 6m 15s) (62400 83%) 0.0010\n",
      "31m 0s (- 6m 13s) (62450 83%) 0.0022\n",
      "31m 1s (- 6m 12s) (62500 83%) 0.0015\n",
      "31m 2s (- 6m 10s) (62550 83%) 0.0040\n",
      "31m 4s (- 6m 9s) (62600 83%) 0.0023\n",
      "31m 5s (- 6m 7s) (62650 83%) 0.0028\n",
      "31m 7s (- 6m 6s) (62700 83%) 0.0029\n",
      "31m 8s (- 6m 4s) (62750 83%) 0.0036\n",
      "31m 10s (- 6m 3s) (62800 83%) 0.0029\n",
      "31m 11s (- 6m 1s) (62850 83%) 0.0040\n",
      "31m 13s (- 6m 0s) (62900 83%) 0.0024\n",
      "31m 15s (- 5m 58s) (62950 83%) 0.0097\n",
      "31m 16s (- 5m 57s) (63000 84%) 0.0030\n",
      "31m 18s (- 5m 55s) (63050 84%) 0.0022\n",
      "31m 19s (- 5m 54s) (63100 84%) 0.0031\n",
      "31m 21s (- 5m 53s) (63150 84%) 0.0020\n",
      "31m 22s (- 5m 51s) (63200 84%) 0.0018\n",
      "31m 24s (- 5m 50s) (63250 84%) 0.0027\n",
      "31m 25s (- 5m 48s) (63300 84%) 0.0078\n",
      "31m 27s (- 5m 47s) (63350 84%) 0.0032\n",
      "31m 28s (- 5m 45s) (63400 84%) 0.0019\n",
      "31m 30s (- 5m 44s) (63450 84%) 0.0027\n",
      "31m 31s (- 5m 42s) (63500 84%) 0.0065\n",
      "31m 33s (- 5m 41s) (63550 84%) 0.0037\n",
      "31m 34s (- 5m 39s) (63600 84%) 0.0048\n",
      "31m 36s (- 5m 38s) (63650 84%) 0.0041\n",
      "31m 37s (- 5m 36s) (63700 84%) 0.0024\n",
      "31m 39s (- 5m 35s) (63750 85%) 0.0032\n",
      "31m 40s (- 5m 33s) (63800 85%) 0.0014\n",
      "31m 42s (- 5m 32s) (63850 85%) 0.0027\n",
      "31m 43s (- 5m 30s) (63900 85%) 0.0020\n",
      "31m 45s (- 5m 29s) (63950 85%) 0.0018\n",
      "31m 46s (- 5m 27s) (64000 85%) 0.0029\n",
      "31m 48s (- 5m 26s) (64050 85%) 0.0019\n",
      "31m 49s (- 5m 24s) (64100 85%) 0.0027\n",
      "31m 50s (- 5m 23s) (64150 85%) 0.0015\n",
      "31m 52s (- 5m 21s) (64200 85%) 0.0017\n",
      "31m 54s (- 5m 20s) (64250 85%) 0.0037\n",
      "31m 55s (- 5m 18s) (64300 85%) 0.0014\n",
      "31m 57s (- 5m 17s) (64350 85%) 0.0014\n",
      "31m 58s (- 5m 15s) (64400 85%) 0.0028\n",
      "31m 59s (- 5m 14s) (64450 85%) 0.0020\n",
      "32m 1s (- 5m 12s) (64500 86%) 0.0049\n",
      "32m 2s (- 5m 11s) (64550 86%) 0.0021\n",
      "32m 4s (- 5m 9s) (64600 86%) 0.0028\n",
      "32m 5s (- 5m 8s) (64650 86%) 0.0038\n",
      "32m 7s (- 5m 6s) (64700 86%) 0.0011\n",
      "32m 8s (- 5m 5s) (64750 86%) 0.0034\n",
      "32m 10s (- 5m 3s) (64800 86%) 0.0038\n",
      "32m 11s (- 5m 2s) (64850 86%) 0.0015\n",
      "32m 13s (- 5m 0s) (64900 86%) 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32m 14s (- 4m 59s) (64950 86%) 0.0020\n",
      "32m 16s (- 4m 57s) (65000 86%) 0.0019\n",
      "32m 18s (- 4m 56s) (65050 86%) 0.0019\n",
      "32m 19s (- 4m 54s) (65100 86%) 0.0024\n",
      "32m 21s (- 4m 53s) (65150 86%) 0.0024\n",
      "32m 22s (- 4m 52s) (65200 86%) 0.0025\n",
      "32m 24s (- 4m 50s) (65250 87%) 0.0015\n",
      "32m 25s (- 4m 49s) (65300 87%) 0.0037\n",
      "32m 27s (- 4m 47s) (65350 87%) 0.0049\n",
      "32m 28s (- 4m 46s) (65400 87%) 0.0043\n",
      "32m 30s (- 4m 44s) (65450 87%) 0.0013\n",
      "32m 31s (- 4m 43s) (65500 87%) 0.0027\n",
      "32m 33s (- 4m 41s) (65550 87%) 0.0070\n",
      "32m 35s (- 4m 40s) (65600 87%) 0.0020\n",
      "32m 36s (- 4m 38s) (65650 87%) 0.0014\n",
      "32m 37s (- 4m 37s) (65700 87%) 0.0019\n",
      "32m 39s (- 4m 35s) (65750 87%) 0.0047\n",
      "32m 40s (- 4m 34s) (65800 87%) 0.0034\n",
      "32m 42s (- 4m 32s) (65850 87%) 0.0020\n",
      "32m 43s (- 4m 31s) (65900 87%) 0.0026\n",
      "32m 45s (- 4m 29s) (65950 87%) 0.0020\n",
      "32m 46s (- 4m 28s) (66000 88%) 0.0119\n",
      "32m 48s (- 4m 26s) (66050 88%) 0.0028\n",
      "32m 49s (- 4m 25s) (66100 88%) 0.0016\n",
      "32m 51s (- 4m 23s) (66150 88%) 0.0020\n",
      "32m 52s (- 4m 22s) (66200 88%) 0.0022\n",
      "32m 54s (- 4m 20s) (66250 88%) 0.0018\n",
      "32m 55s (- 4m 19s) (66300 88%) 0.0047\n",
      "32m 57s (- 4m 17s) (66350 88%) 0.0027\n",
      "32m 58s (- 4m 16s) (66400 88%) 0.0041\n",
      "32m 59s (- 4m 14s) (66450 88%) 0.0021\n",
      "33m 1s (- 4m 13s) (66500 88%) 0.0043\n",
      "33m 2s (- 4m 11s) (66550 88%) 0.0018\n",
      "33m 4s (- 4m 10s) (66600 88%) 0.0049\n",
      "33m 6s (- 4m 8s) (66650 88%) 0.0034\n",
      "33m 7s (- 4m 7s) (66700 88%) 0.0023\n",
      "33m 9s (- 4m 5s) (66750 89%) 0.0014\n",
      "33m 10s (- 4m 4s) (66800 89%) 0.0028\n",
      "33m 12s (- 4m 2s) (66850 89%) 0.0018\n",
      "33m 13s (- 4m 1s) (66900 89%) 0.0030\n",
      "33m 15s (- 3m 59s) (66950 89%) 0.0040\n",
      "33m 16s (- 3m 58s) (67000 89%) 0.0055\n",
      "33m 18s (- 3m 56s) (67050 89%) 0.0024\n",
      "33m 19s (- 3m 55s) (67100 89%) 0.0015\n",
      "33m 21s (- 3m 53s) (67150 89%) 0.0023\n",
      "33m 22s (- 3m 52s) (67200 89%) 0.0036\n",
      "33m 24s (- 3m 50s) (67250 89%) 0.0079\n",
      "33m 25s (- 3m 49s) (67300 89%) 0.0029\n",
      "33m 27s (- 3m 48s) (67350 89%) 0.0025\n",
      "33m 28s (- 3m 46s) (67400 89%) 0.0041\n",
      "33m 30s (- 3m 45s) (67450 89%) 0.0031\n",
      "33m 31s (- 3m 43s) (67500 90%) 0.0026\n",
      "33m 33s (- 3m 42s) (67550 90%) 0.0086\n",
      "33m 34s (- 3m 40s) (67600 90%) 0.0021\n",
      "33m 36s (- 3m 39s) (67650 90%) 0.0030\n",
      "33m 37s (- 3m 37s) (67700 90%) 0.0034\n",
      "33m 39s (- 3m 36s) (67750 90%) 0.0011\n",
      "33m 40s (- 3m 34s) (67800 90%) 0.0017\n",
      "33m 42s (- 3m 33s) (67850 90%) 0.0012\n",
      "33m 43s (- 3m 31s) (67900 90%) 0.0039\n",
      "33m 45s (- 3m 30s) (67950 90%) 0.0020\n",
      "33m 46s (- 3m 28s) (68000 90%) 0.0028\n",
      "33m 48s (- 3m 27s) (68050 90%) 0.0031\n",
      "33m 49s (- 3m 25s) (68100 90%) 0.0036\n",
      "33m 51s (- 3m 24s) (68150 90%) 0.0014\n",
      "33m 52s (- 3m 22s) (68200 90%) 0.0029\n",
      "33m 54s (- 3m 21s) (68250 91%) 0.0030\n",
      "33m 55s (- 3m 19s) (68300 91%) 0.0015\n",
      "33m 57s (- 3m 18s) (68350 91%) 0.0011\n",
      "33m 58s (- 3m 16s) (68400 91%) 0.0028\n",
      "34m 0s (- 3m 15s) (68450 91%) 0.0023\n",
      "34m 1s (- 3m 13s) (68500 91%) 0.0030\n",
      "34m 3s (- 3m 12s) (68550 91%) 0.0017\n",
      "34m 4s (- 3m 10s) (68600 91%) 0.0016\n",
      "34m 6s (- 3m 9s) (68650 91%) 0.0037\n",
      "34m 7s (- 3m 7s) (68700 91%) 0.0026\n",
      "34m 9s (- 3m 6s) (68750 91%) 0.0026\n",
      "34m 10s (- 3m 4s) (68800 91%) 0.0023\n",
      "34m 12s (- 3m 3s) (68850 91%) 0.0019\n",
      "34m 13s (- 3m 1s) (68900 91%) 0.0029\n",
      "34m 15s (- 3m 0s) (68950 91%) 0.0019\n",
      "34m 16s (- 2m 58s) (69000 92%) 0.0015\n",
      "34m 18s (- 2m 57s) (69050 92%) 0.0029\n",
      "34m 19s (- 2m 55s) (69100 92%) 0.0013\n",
      "34m 21s (- 2m 54s) (69150 92%) 0.0037\n",
      "34m 22s (- 2m 52s) (69200 92%) 0.0013\n",
      "34m 24s (- 2m 51s) (69250 92%) 0.0015\n",
      "34m 25s (- 2m 49s) (69300 92%) 0.0015\n",
      "34m 27s (- 2m 48s) (69350 92%) 0.0028\n",
      "34m 28s (- 2m 46s) (69400 92%) 0.0020\n",
      "34m 29s (- 2m 45s) (69450 92%) 0.0018\n",
      "34m 31s (- 2m 43s) (69500 92%) 0.0019\n",
      "34m 32s (- 2m 42s) (69550 92%) 0.0016\n",
      "34m 34s (- 2m 40s) (69600 92%) 0.0016\n",
      "34m 35s (- 2m 39s) (69650 92%) 0.0050\n",
      "34m 37s (- 2m 37s) (69700 92%) 0.0028\n",
      "34m 39s (- 2m 36s) (69750 93%) 0.0021\n",
      "34m 40s (- 2m 34s) (69800 93%) 0.0034\n",
      "34m 42s (- 2m 33s) (69850 93%) 0.0021\n",
      "34m 43s (- 2m 32s) (69900 93%) 0.0033\n",
      "34m 45s (- 2m 30s) (69950 93%) 0.0014\n",
      "34m 46s (- 2m 29s) (70000 93%) 0.0025\n",
      "34m 48s (- 2m 27s) (70050 93%) 0.0051\n",
      "34m 49s (- 2m 26s) (70100 93%) 0.0011\n",
      "34m 51s (- 2m 24s) (70150 93%) 0.0016\n",
      "34m 52s (- 2m 23s) (70200 93%) 0.0012\n",
      "34m 54s (- 2m 21s) (70250 93%) 0.0025\n",
      "34m 55s (- 2m 20s) (70300 93%) 0.0028\n",
      "34m 57s (- 2m 18s) (70350 93%) 0.0017\n",
      "34m 58s (- 2m 17s) (70400 93%) 0.0027\n",
      "35m 0s (- 2m 15s) (70450 93%) 0.0013\n",
      "35m 1s (- 2m 14s) (70500 94%) 0.0033\n",
      "35m 3s (- 2m 12s) (70550 94%) 0.0010\n",
      "35m 4s (- 2m 11s) (70600 94%) 0.0044\n",
      "35m 6s (- 2m 9s) (70650 94%) 0.0023\n",
      "35m 7s (- 2m 8s) (70700 94%) 0.0018\n",
      "35m 8s (- 2m 6s) (70750 94%) 0.0015\n",
      "35m 10s (- 2m 5s) (70800 94%) 0.0028\n",
      "35m 11s (- 2m 3s) (70850 94%) 0.0013\n",
      "35m 13s (- 2m 2s) (70900 94%) 0.0026\n",
      "35m 14s (- 2m 0s) (70950 94%) 0.0014\n",
      "35m 15s (- 1m 59s) (71000 94%) 0.0027\n",
      "35m 17s (- 1m 57s) (71050 94%) 0.0051\n",
      "35m 19s (- 1m 56s) (71100 94%) 0.0025\n",
      "35m 20s (- 1m 54s) (71150 94%) 0.0044\n",
      "35m 21s (- 1m 53s) (71200 94%) 0.0055\n",
      "35m 23s (- 1m 51s) (71250 95%) 0.0018\n",
      "35m 24s (- 1m 50s) (71300 95%) 0.0027\n",
      "35m 26s (- 1m 48s) (71350 95%) 0.0040\n",
      "35m 27s (- 1m 47s) (71400 95%) 0.0109\n",
      "35m 29s (- 1m 45s) (71450 95%) 0.0056\n",
      "35m 30s (- 1m 44s) (71500 95%) 0.0040\n",
      "35m 32s (- 1m 42s) (71550 95%) 0.0022\n",
      "35m 33s (- 1m 41s) (71600 95%) 0.0014\n",
      "35m 35s (- 1m 39s) (71650 95%) 0.0013\n",
      "35m 36s (- 1m 38s) (71700 95%) 0.0020\n",
      "35m 38s (- 1m 36s) (71750 95%) 0.0015\n",
      "35m 39s (- 1m 35s) (71800 95%) 0.0016\n",
      "35m 41s (- 1m 33s) (71850 95%) 0.0020\n",
      "35m 42s (- 1m 32s) (71900 95%) 0.0014\n",
      "35m 44s (- 1m 30s) (71950 95%) 0.0034\n",
      "35m 46s (- 1m 29s) (72000 96%) 0.0039\n",
      "35m 47s (- 1m 27s) (72050 96%) 0.0025\n",
      "35m 49s (- 1m 26s) (72100 96%) 0.0019\n",
      "35m 50s (- 1m 24s) (72150 96%) 0.0020\n",
      "35m 52s (- 1m 23s) (72200 96%) 0.0062\n",
      "35m 53s (- 1m 21s) (72250 96%) 0.0058\n",
      "35m 55s (- 1m 20s) (72300 96%) 0.0030\n",
      "35m 56s (- 1m 19s) (72350 96%) 0.0025\n",
      "35m 58s (- 1m 17s) (72400 96%) 0.0023\n",
      "36m 0s (- 1m 16s) (72450 96%) 0.0033\n",
      "36m 1s (- 1m 14s) (72500 96%) 0.0024\n",
      "36m 3s (- 1m 13s) (72550 96%) 0.0017\n",
      "36m 4s (- 1m 11s) (72600 96%) 0.0030\n",
      "36m 6s (- 1m 10s) (72650 96%) 0.0030\n",
      "36m 7s (- 1m 8s) (72700 96%) 0.0011\n",
      "36m 9s (- 1m 7s) (72750 97%) 0.0028\n",
      "36m 10s (- 1m 5s) (72800 97%) 0.0033\n",
      "36m 12s (- 1m 4s) (72850 97%) 0.0025\n",
      "36m 13s (- 1m 2s) (72900 97%) 0.0017\n",
      "36m 15s (- 1m 1s) (72950 97%) 0.0022\n",
      "36m 16s (- 0m 59s) (73000 97%) 0.0025\n",
      "36m 18s (- 0m 58s) (73050 97%) 0.0016\n",
      "36m 19s (- 0m 56s) (73100 97%) 0.0027\n",
      "36m 21s (- 0m 55s) (73150 97%) 0.0016\n",
      "36m 22s (- 0m 53s) (73200 97%) 0.0010\n",
      "36m 24s (- 0m 52s) (73250 97%) 0.0021\n",
      "36m 25s (- 0m 50s) (73300 97%) 0.0016\n",
      "36m 27s (- 0m 49s) (73350 97%) 0.0020\n",
      "36m 28s (- 0m 47s) (73400 97%) 0.0023\n",
      "36m 30s (- 0m 46s) (73450 97%) 0.0012\n",
      "36m 31s (- 0m 44s) (73500 98%) 0.0016\n",
      "36m 33s (- 0m 43s) (73550 98%) 0.0017\n",
      "36m 34s (- 0m 41s) (73600 98%) 0.0027\n",
      "36m 35s (- 0m 40s) (73650 98%) 0.0021\n",
      "36m 37s (- 0m 38s) (73700 98%) 0.0016\n",
      "36m 39s (- 0m 37s) (73750 98%) 0.0028\n",
      "36m 40s (- 0m 35s) (73800 98%) 0.0008\n",
      "36m 42s (- 0m 34s) (73850 98%) 0.0012\n",
      "36m 43s (- 0m 32s) (73900 98%) 0.1945\n",
      "36m 45s (- 0m 31s) (73950 98%) 0.0030\n",
      "36m 46s (- 0m 29s) (74000 98%) 0.0107\n",
      "36m 48s (- 0m 28s) (74050 98%) 0.0027\n",
      "36m 49s (- 0m 26s) (74100 98%) 0.0025\n",
      "36m 51s (- 0m 25s) (74150 98%) 0.0117\n",
      "36m 52s (- 0m 23s) (74200 98%) 0.0033\n",
      "36m 54s (- 0m 22s) (74250 99%) 0.0031\n",
      "36m 55s (- 0m 20s) (74300 99%) 0.0020\n",
      "36m 57s (- 0m 19s) (74350 99%) 0.0033\n",
      "36m 59s (- 0m 17s) (74400 99%) 0.0063\n",
      "37m 0s (- 0m 16s) (74450 99%) 0.0064\n",
      "37m 2s (- 0m 14s) (74500 99%) 0.0043\n",
      "37m 3s (- 0m 13s) (74550 99%) 0.0062\n",
      "37m 5s (- 0m 11s) (74600 99%) 0.0052\n",
      "37m 6s (- 0m 10s) (74650 99%) 0.0026\n",
      "37m 8s (- 0m 8s) (74700 99%) 0.0030\n",
      "37m 9s (- 0m 7s) (74750 99%) 0.0041\n",
      "37m 11s (- 0m 5s) (74800 99%) 0.0019\n",
      "37m 12s (- 0m 4s) (74850 99%) 0.0033\n",
      "37m 14s (- 0m 2s) (74900 99%) 0.0023\n",
      "37m 15s (- 0m 1s) (74950 99%) 0.0025\n",
      "37m 17s (- 0m 0s) (75000 100%) 0.0022\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "counter=1\n",
    "name = \"agreement_\"+str(counter)+\".pt\"\n",
    "print(name)\n",
    "\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=50)\n",
    "\n",
    "torch.save(model.state_dict(),name)   \n",
    "counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> our bird does confuse some elephant around our bird . quest\n",
      "= does our bird confuse some elephant around our bird ? quest\n",
      "< does our bird confuse some elephant around our bird ? <QUEST>\n",
      "\n",
      "> our seal doesnt irritate our seal . quest\n",
      "= doesnt our seal irritate our seal ? quest\n",
      "< doesnt our seal irritate our seal ? <QUEST>\n",
      "\n",
      "> your elephant by your yaks does entertain the dog by your yak . quest\n",
      "= does your elephant by your yaks entertain the dog by your yak ? quest\n",
      "< does your elephant by your yaks entertain the dog by your yak ? <QUEST>\n",
      "\n",
      "> her birds that dont sleep dont call her seals . ident\n",
      "= her birds that dont sleep dont call her seals . ident\n",
      "< her birds that dont sleep dont call her seals <IDENT>\n",
      "\n",
      "> her cats dont admire your rabbits . ident\n",
      "= her cats dont admire your rabbits . ident\n",
      "< her cats dont admire your rabbits <IDENT>\n",
      "\n",
      "> some bird upon our bird doesnt confuse some rabbits . quest\n",
      "= doesnt some bird upon our bird confuse some rabbits ? quest\n",
      "< doesnt some bird upon our bird confuse some rabbits ? <QUEST>\n",
      "\n",
      "> your monkey with your rabbits does giggle . ident\n",
      "= your monkey with your rabbits does giggle . ident\n",
      "< your monkey with your rabbits does giggle <IDENT>\n",
      "\n",
      "> some yak doesnt impress my yak . quest\n",
      "= doesnt some yak impress my yak ? quest\n",
      "< doesnt some yak impress my yak ? <QUEST>\n",
      "\n",
      "> our monkey does confuse your monkeys who dont entertain our cats . quest\n",
      "= does our monkey confuse your monkeys who dont entertain our cats ? quest\n",
      "< does our monkey confuse your monkeys who dont entertain our cats ? <QUEST>\n",
      "\n",
      "> your dog who doesnt laugh doesnt entertain our dog . ident\n",
      "= your dog who doesnt laugh doesnt entertain our dog . ident\n",
      "< your dog who doesnt laugh doesnt entertain our dog <IDENT>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Attention\n",
    "---------------------\n",
    "\n",
    "A useful property of the attention mechanism is its highly interpretable\n",
    "outputs. Because it is used to weight specific encoder outputs of the\n",
    "input sequence, we can imagine looking where the network is focused most\n",
    "at each time step.\n",
    "\n",
    "You could simply run ``plt.matshow(attentions)`` to see attention output\n",
    "displayed as a matrix, with the columns being input steps and rows being\n",
    "output steps:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3010f49630>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"our cats do read quest\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better viewing experience we will do the extra work of adding axes\n",
    "and labels:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = her dog who does smile doesnt confuse your dog who does confuse your unicorn . quest\n",
      "output = does her dog who doesnt smile does confuse your dog who does confuse your unicorn ? <QUEST>\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<end>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(input_sentence+'.png')\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"her dog who does smile doesnt confuse your dog who does confuse your unicorn . quest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['does', 'her', 'dog', 'who', 'doesnt', 'smile', 'does', 'confuse', 'your', 'dog', 'who', 'does', 'confuse', 'your', 'unicorn']\n"
     ]
    }
   ],
   "source": [
    "lines = open(input_file_path+'test.txt' ,).\\\n",
    "        read().strip().split('\\n')\n",
    "input_sentences = [] \n",
    "output_sentences = []\n",
    "predicted_sentences = []\n",
    "full_sentence_word_match_counter = 0\n",
    "full_sentence_pos_match_counter = 0\n",
    "total_sentences_counter = 0\n",
    "from eval import *\n",
    "for line in lines:\n",
    "    sentences = line.split(\"\\t\")\n",
    "    input_sent = sentences[0]\n",
    "    output_sent = sentences[1]\n",
    "    input_sentences.append(input_sent)\n",
    "    output_sentences.append(output_sent)\n",
    "    outwords , out_attn = evaluate(encoder1,attn_decoder1,input_sent)\n",
    "    predicted_sentence = \" \".join(outwords)\n",
    "    predicted_sentences.append(predicted_sentence)\n",
    "    final_pred = outwords[:len(outwords)-2]\n",
    "    expected = output_sent.split(\" \")\n",
    "    final_expected = expected[:len(outwords)-2]\n",
    "    if full_sentence_word_match(final_pred,final_expected):\n",
    "        full_sentence_word_match_counter+=1\n",
    "    if full_sentence_pos_match(final_pred,final_expected,agreement):\n",
    "        full_sentence_pos_match_counter+=1\n",
    "    total_sentences_counter+=1\n",
    "    \n",
    "predictions = open(input_file_path+\"predictions.txt\",\"w\")\n",
    "for index in range(total_sentences_counter):\n",
    "    predictions.write(str(index)+\".\\n\")\n",
    "    predictions.write(\"Input:\"+input_sentences[index] + \"\\n\")\n",
    "    predictions.write(\"Expected Output:\" + output_sentences[index]+\"\\n\")\n",
    "    predictions.write(\"Predicted:\" + predicted_sentences[index] + \"\\n\")\n",
    "predictions.close()\n",
    "\n",
    "report = open(input_file_path+\"report.txt\" , \"w\")\n",
    "report.write(\"Total number Of sentences:\" + str(total_sentences_counter) + \"\\n\")\n",
    "report.write(\"Total number of correct full sentences word match:\" + str(full_sentence_word_match_counter) + \"\\n\")\n",
    "report.write(\"Total number of correct full sentences pos match:\" + str(full_sentence_pos_match_counter) + \"\\n\")\n",
    "report.close()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq",
   "language": "python",
   "name": "seq2seq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
